{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.data_loader import load_from_tsfile_to_dataframe\n",
    "from utils.regressor_tools import process_data\n",
    "#import mlflow\n",
    "#from tsfeatures import tsfeatures\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "#pd.set_option('display.max_rows', None)  \n",
    "#pd.set_option('display.max_columns', None) \n",
    "from utils.personal_utils import *\n",
    "from compression import *\n",
    "from utils.compression_algos import *\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing Notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:01, 57.40it/s] \n",
      "100%|██████████| 42/42 [00:00<00:00, 643.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Testing of compress_dataset\n",
    "data_path = \"/home/sim/Desktop/TS Extrinsic Regression/data/AppliancesEnergy_TEST.ts\"\n",
    "dataset_array = load_dataset(data_path)\n",
    "dataset_id = os.path.basename(data_path).split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sim/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/polynomial/chebyshev.py:1436: RuntimeWarning: overflow encountered in multiply\n",
      "  v[i] = v[i-1]*x2 - v[i-2]\n",
      "/home/sim/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/polynomial/chebyshev.py:1436: RuntimeWarning: invalid value encountered in subtract\n",
      "  v[i] = v[i-1]*x2 - v[i-2]\n",
      "/home/sim/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/polynomial/polyutils.py:660: RuntimeWarning: overflow encountered in square\n",
      "  scl = np.sqrt(np.square(lhs).sum(1))\n",
      "/home/sim/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/core/_methods.py:49: RuntimeWarning: overflow encountered in reduce\n",
      "  return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "/home/sim/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/polynomial/polyutils.py:664: RuntimeWarning: invalid value encountered in divide\n",
      "  c, resids, rank, s = np.linalg.lstsq(lhs.T/scl, rhs.T, rcond)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ** On entry to DLASCL parameter number  4 had an illegal value\n",
      " ** On entry to DLASCL parameter number  4 had an illegal value\n"
     ]
    },
    {
     "ename": "LinAlgError",
     "evalue": "SVD did not converge in Linear Least Squares",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[38;5;241m=\u001b[39m dataset_array[\u001b[38;5;241m0\u001b[39m,:,\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#b = cpt_compress(a, 0, True)\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mcpt_compress\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a figure and axis\u001b[39;00m\n\u001b[1;32m      5\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/TSER Code/utils/compression_algos.py:192\u001b[0m, in \u001b[0;36mcpt_compress\u001b[0;34m(signal, dropout_ratio, andDecompress)\u001b[0m\n\u001b[1;32m    189\u001b[0m t \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(signal))\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Get the coefficients. deg is the longest that is possible. Shouldn't take too long to calculate.\u001b[39;00m\n\u001b[0;32m--> 192\u001b[0m cpt_coeffs \u001b[38;5;241m=\u001b[39m \u001b[43mchebfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Calculate the number of coefficients to zero out\u001b[39;00m\n\u001b[1;32m    195\u001b[0m num_coeffs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((dropout_ratio) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(cpt_coeffs))\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/polynomial/chebyshev.py:1671\u001b[0m, in \u001b[0;36mchebfit\u001b[0;34m(x, y, deg, rcond, full, w)\u001b[0m\n\u001b[1;32m   1547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchebfit\u001b[39m(x, y, deg, rcond\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, full\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;124;03m    Least squares fit of Chebyshev series to data.\u001b[39;00m\n\u001b[1;32m   1550\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1669\u001b[0m \n\u001b[1;32m   1670\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1671\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchebvander\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/polynomial/polyutils.py:664\u001b[0m, in \u001b[0;36m_fit\u001b[0;34m(vander_f, x, y, deg, rcond, full, w)\u001b[0m\n\u001b[1;32m    661\u001b[0m scl[scl \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;66;03m# Solve the least squares problem.\u001b[39;00m\n\u001b[0;32m--> 664\u001b[0m c, resids, rank, s \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstsq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mscl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    665\u001b[0m c \u001b[38;5;241m=\u001b[39m (c\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m/\u001b[39mscl)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m    667\u001b[0m \u001b[38;5;66;03m# Expand c to include non-fitted coefficients which are set to zero\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/linalg/linalg.py:2326\u001b[0m, in \u001b[0;36mlstsq\u001b[0;34m(a, b, rcond)\u001b[0m\n\u001b[1;32m   2323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_rhs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2324\u001b[0m     \u001b[38;5;66;03m# lapack can't handle n_rhs = 0 - so allocate the array one larger in that axis\u001b[39;00m\n\u001b[1;32m   2325\u001b[0m     b \u001b[38;5;241m=\u001b[39m zeros(b\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (m, n_rhs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), dtype\u001b[38;5;241m=\u001b[39mb\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m-> 2326\u001b[0m x, resids, rank, s \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   2328\u001b[0m     x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/linalg/linalg.py:124\u001b[0m, in \u001b[0;36m_raise_linalgerror_lstsq\u001b[0;34m(err, flag)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_raise_linalgerror_lstsq\u001b[39m(err, flag):\n\u001b[0;32m--> 124\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVD did not converge in Linear Least Squares\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: SVD did not converge in Linear Least Squares"
     ]
    }
   ],
   "source": [
    "a = dataset_array[0,:,0]\n",
    "#b = cpt_compress(a, 0, True)\n",
    "c = cpt_compress(a, 0, True)\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the arrays\n",
    "ax.plot(a, label='Array a')\n",
    "#ax.plot(b, label='Array b')\n",
    "ax.plot(c, label='Array c')\n",
    "\n",
    "# Add a legend\n",
    "ax.legend()\n",
    "\n",
    "# Add labels and title\n",
    "ax.set_xlabel('X axis')\n",
    "ax.set_ylabel('Y axis')\n",
    "ax.set_title('Plot of Array a and Array b')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.851846160185703e-16\n",
      "5.994167284957842e-05\n",
      "0.00022564096301173659\n",
      "0.000498392537192524\n",
      "0.0009079286054607782\n",
      "0.0014373117013685608\n",
      "0.0020974867412751805\n",
      "0.0029222095789197635\n",
      "0.003899100057827952\n",
      "0.005039237528055976\n",
      "0.00642090155338893\n",
      "0.008003246174774057\n",
      "0.009844885731779605\n",
      "0.012029494478170297\n",
      "0.014550804904737409\n",
      "0.01754779942202451\n",
      "0.021276439190341754\n",
      "0.02578320273958115\n",
      "0.031535565228530724\n",
      "0.039473669418568606\n",
      "0.05058808413238885\n",
      "0.06780372088937132\n",
      "0.09815548434950953\n",
      "0.15874979564310218\n",
      "0.33841182905854544\n",
      "0.9990079365079365\n"
     ]
    }
   ],
   "source": [
    "# Check if RMSE increases with increasing dropout_ratio\n",
    "for i in np.arange(0, 1.04, 0.04):\n",
    "    decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, True, \"dwt\", i) \n",
    "    print(compute_avg_rmse_of_dataset(dataset_array, decompressed_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.09, 0.18, 0.27, 0.36, 0.45, 0.54, 0.63, 0.72, 0.81, 0.9 ,\n",
       "       0.99])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 1.0, 0.09)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6100030359173055\n",
      "0.6590095913020394\n",
      "0.7243691331150536\n",
      "0.806204970895446\n",
      "0.9094634146341464\n",
      "1.0477120335186134\n",
      "1.2408534266372557\n",
      "1.5305863956215793\n",
      "2.002592505991699\n",
      "2.9267758208993477\n",
      "5.418567316209034\n",
      "40.5664298401421\n"
     ]
    }
   ],
   "source": [
    "# Check that Compression Ratio increases with increasing dropout_ratio\n",
    "for i in np.arange(0, 1, 0.09):\n",
    "    decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, False, \"dct\", i) \n",
    "    print(calculateCompRatio(dataset_array, decompressed_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantization Testing: Test the returnd dtyps of the transforms\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.fft import dct, idct, fft, ifft\n",
    "import pywt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23]\n",
      "  [24 25 26 27]\n",
      "  [28 29 30 31]\n",
      "  [32 33 34 35]\n",
      "  [36 37 38 39]]]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]\n",
      " [24 25 26 27]\n",
      " [28 29 30 31]\n",
      " [32 33 34 35]\n",
      " [36 37 38 39]]\n",
      "[ 0  4  8 12 16 20 24 28 32 36  1  5  9 13 17 21 25 29 33 37  2  6 10 14\n",
      " 18 22 26 30 34 38  3  7 11 15 19 23 27 31 35 39]\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23]\n",
      "  [24 25 26 27]\n",
      "  [28 29 30 31]\n",
      "  [32 33 34 35]\n",
      "  [36 37 38 39]]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "# Test if reshaping from (len_flat_dim, dim) to (num_dp, len_ts, dim) is working\n",
    "num_dp = 2\n",
    "len_ts = 5\n",
    "num_dim = 4\n",
    "\n",
    "array = np.arange(num_dp * len_ts * num_dim).reshape(num_dp, len_ts, num_dim)\n",
    "print(array)\n",
    "\n",
    "# Reshape to (len_flat_dim, dim)\n",
    "array_flatdim = array.reshape(num_dp * len_ts, num_dim)\n",
    "print(array_flatdim)\n",
    "\n",
    "# Put column after column. For gzip part.\n",
    "print(array_flatdim.reshape(-1, order='F'))\n",
    "\n",
    "\n",
    "# Reshape back to (num_dp, len_ts, dim)\n",
    "array_back = array_flatdim.reshape(-1, len_ts, num_dim)\n",
    "print(array_back)\n",
    "\n",
    "print(array_back.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "int64\n",
      "<class 'bytearray'>\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Test binary conversion and compression\n",
    "num_dp = 2\n",
    "len_ts = 2\n",
    "num_dim = 2\n",
    "\n",
    "array = np.arange(num_dp * len_ts * num_dim).reshape(num_dp, len_ts, num_dim)\n",
    "array_flat = array.reshape(num_dp * len_ts, num_dim)\n",
    "\n",
    "# Test if .tobytes saves metadata of the np.array -> No it flattens the array row after row (and slice after slice), then just saves the content of the array as bytes!\n",
    "print(array_flat.tobytes() == np.arange(8).tobytes())\n",
    "\n",
    "\n",
    "byte_nparray = np.arange(5)\n",
    "print(byte_nparray.dtype)\n",
    "\n",
    "byte_nparray = byte_nparray.tobytes()\n",
    "\n",
    "print(bytearray)\n",
    "print(len(byte_nparray))\n",
    "\n",
    "# len(byte-string) -> return number of bytes in byte-object!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if saving with tofile keeps the array the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test Saving in Files\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_series.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtrain_x_p\u001b[49m)\n\u001b[1;32m      4\u001b[0m train_x_p[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m      7\u001b[0m flattened \u001b[38;5;241m=\u001b[39m train_x_p\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_p' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Saving in Files\n",
    "\n",
    "np.save('time_series.npy', train_x_p)\n",
    "train_x_p[0][0][0].dtype\n",
    "\n",
    "\n",
    "flattened = train_x_p.flatten()\n",
    "flattened.tofile(\"data.bin\")\n",
    "\n",
    "train_after = np.fromfile(\"data.bin\", dtype=train_x_p[0][0][0].dtype)\n",
    "train_after.shape\n",
    "if np.array_equal(flattened, train_after):\n",
    "    print(\"The arrays have the same content.\")\n",
    "else:\n",
    "    print(\"The arrays do not have the same content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only preparing Data for Testing!\n",
    "\n",
    "def prepare_data(data_x_p, data_y):\n",
    "\n",
    "    # Swap the dimensions so that columns are stacked after each other. Copy since swapaxes only returns a view\n",
    "    #(95, 144, 24) -> (95, 24, 144), first column gets first row etc. One Row is the ts of the belonging dimension.\n",
    "    data_swapped = data_x_p.swapaxes(1, 2).copy()\n",
    "\n",
    "    # Reshape to flattened ts. Stack the rows behind the other for each slice.\n",
    "    data_x_flattend = data_swapped.reshape(data_swapped.shape[0], -1)\n",
    "    \n",
    "\n",
    "    prep_data = pd.DataFrame(data_x_flattend)\n",
    "    prep_data['target'] = data_y\n",
    "    prep_data.columns = prep_data.columns.astype(str) #fwiz or flaml needs string as columns!\n",
    "\n",
    "   \n",
    "    #data_x_p = data_x_p[0:2,...]\n",
    "\n",
    "    num_datapoints = data_x_p.shape[0]\n",
    "    len_timeseries = data_x_p.shape[1]\n",
    "    num_dimensions = data_x_p.shape[2]\n",
    "    num_features = 38\n",
    "\n",
    "    all_features = np.ndarray((num_datapoints, num_features * num_dimensions))\n",
    "\n",
    "    for i in range(0, num_datapoints):\n",
    "        start_index = 0\n",
    "\n",
    "        for j in range(0, num_dimensions):\n",
    "            curr_ts = data_x_p[i,:,j]\n",
    "\n",
    "            #print(curr_ts.size)\n",
    "\n",
    "            timeseries_df = pd.DataFrame({'unique_id' : np.ones(len_timeseries),'ds': np.arange(0, len_timeseries) , 'y': curr_ts})\n",
    "            \n",
    "            feature_array = tsfeatures(timeseries_df, freq=1).fillna(0).values\n",
    "\n",
    "            #print(feature_array.size)\n",
    "            #print(np.isnan(feature_array).sum())\n",
    "\n",
    "            end_index = start_index + feature_array.size\n",
    "            all_features[i, start_index: end_index] = feature_array\n",
    "            start_index = end_index\n",
    "        \n",
    "\n",
    "    all_features = pd.DataFrame(all_features)\n",
    "\n",
    "    # name the features\n",
    "    for i, col in enumerate(all_features.columns):\n",
    "        # Generate the new column name\n",
    "        new_col_name = 'f' + str(i + 1)\n",
    "        # Rename the column\n",
    "        all_features.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ts_and_features = pd.concat([prep_data, all_features], axis=1)\n",
    "\n",
    "\n",
    "    all_features['target'] = data_y\n",
    "\n",
    "    ts_and_features = pd.concat([prep_data.drop(columns=['target']), all_features], axis=1)\n",
    "    \n",
    "    #prep_data.columns = prep_data.columns.astype(str)\n",
    "\n",
    "    return ts_and_features, all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test preparing part function of load_and_prepare_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00000000e+00  3.74540119e-01]\n",
      "  [ 1.00000000e+00  9.50714306e-01]\n",
      "  [ 2.00000000e+00  7.31993942e-01]]\n",
      "\n",
      " [[ 0.00000000e+00  7.49080238e-02]\n",
      "  [ 1.22464680e-16  1.19014286e+00]\n",
      "  [-2.44929360e-16  2.14639879e+00]]]\n",
      "[[ 1.00000000e+00  5.00000000e-01  3.00000000e+00  4.44089210e-16\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.35200499e+02  0.00000000e+00  9.99999985e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  6.66801831e-01  3.00000000e+00 -2.75921612e+00\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.15119426e+02  0.00000000e+00  1.49011612e-08  1.47344817e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  2.00000000e+00  0.00000000e+00\n",
      "  -4.14940655e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  7.15004181e-01  3.00000000e+00 -8.00000000e+00\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.41667483e+02  0.00000000e+00  1.49011613e-08  1.47776810e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.26435418e-31  2.00000000e+00  0.00000000e+00\n",
      "  -3.80952381e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  5.59880864e-01  3.00000000e+00 -2.85103917e-01\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   6.95053958e+02  0.00000000e+00  1.49011612e-08  1.22257941e-11\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  8.75840729e-31  1.00000000e+00  0.00000000e+00\n",
      "  -1.30631734e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "     0             1             2         3         4         5   f1  \\\n",
      "0  0.0  1.000000e+00  2.000000e+00  0.374540  0.950714  0.731994  1.0   \n",
      "1  0.0  1.224647e-16 -2.449294e-16  0.074908  1.190143  2.146399  1.0   \n",
      "\n",
      "         f2   f3            f4  ...           f68  f69  f70       f71  f72  \\\n",
      "0  0.500000  3.0  4.440892e-16  ... -0.000000e+00  2.0  0.0 -0.414941  0.0   \n",
      "1  0.715004  3.0 -8.000000e+00  ...  8.758407e-31  1.0  0.0 -0.001306  0.0   \n",
      "\n",
      "   f73  f74  f75  f76  target  \n",
      "0  0.0  0.0  0.0  0.0       0  \n",
      "1  0.0  0.0  0.0  0.0       1  \n",
      "\n",
      "[2 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "# Simple test:\n",
    "#-> No a perfect test, but it seems to work! I have no idea about better tests!\n",
    "\n",
    "len_ts = 3\n",
    "ts_1_v = np.arange(len_ts)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "ts_2_v = np.random.rand(len_ts)\n",
    "x = np.linspace(0, 2 * np.pi, len_ts)\n",
    "ts_3_v = np.sin(x)\n",
    "\n",
    "ts_4_v =  ts_1_v + 0.2 * ts_2_v\n",
    "\n",
    "\n",
    "# Reulting Feature matrix\n",
    "ts_1 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_1_v})\n",
    "ts_2 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_2_v})\n",
    "ts_3 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_3_v})\n",
    "ts_4 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_4_v})\n",
    "\n",
    "feature_matrix = np.vstack((tsfeatures(ts_1, freq=1).fillna(0).values, tsfeatures(ts_2, freq=1).fillna(0).values, tsfeatures(ts_3, freq=1).fillna(0).values,tsfeatures(ts_4, freq=1).fillna(0).values))\n",
    "#print(feature_matrix)\n",
    "\n",
    "\n",
    "layer1 = np.stack((ts_1_v, ts_2_v), axis=1)\n",
    "layer2 = np.stack((ts_3_v,ts_4_v), axis=1)\n",
    "\n",
    "input = np.stack((layer1, layer2), axis=0)\n",
    "\n",
    "\n",
    "print(input)\n",
    "print(feature_matrix)\n",
    "tsf, f = prepare_data(input, np.arange(2))\n",
    "print(tsf)\n",
    "#print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1    2    3    4    5    6    7    8    9  ...      f144  f145  \\\n",
       " 0    0    4    8   12   16   20   24   28   32   36  ...  0.521199   1.0   \n",
       " 1  120  124  128  132  136  140  144  148  152  156  ...  0.521199   1.0   \n",
       " 2  240  244  248  252  256  260  264  268  272  276  ...  0.521199   1.0   \n",
       " \n",
       "    f146  f147      f148      f149      f150      f151     f152    target  \n",
       " 0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.388170  \n",
       " 1   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.643288  \n",
       " 2   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.458253  \n",
       " \n",
       " [3 rows x 273 columns],\n",
       "     f1        f2    f3   f4        f5   f6   f7   f8        f9  f10  ...  \\\n",
       " 0  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " 1  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " 2  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " \n",
       "        f144  f145  f146  f147      f148      f149      f150      f151  \\\n",
       " 0  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " 1  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " 2  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " \n",
       "       f152    target  \n",
       " 0  0.53624  0.388170  \n",
       " 1  0.53624  0.643288  \n",
       " 2  0.53624  0.458253  \n",
       " \n",
       " [3 rows x 153 columns])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Sample TS\n",
    "linear_data = linear_data = np.arange(360).reshape(3, 30, 4)  # Creates an array with values from 0 to 1199\n",
    "linear_data\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "random_data = np.random.rand(3, 30, 4)\n",
    "random_y = np.random.rand(3)\n",
    "random_data\n",
    "\n",
    "prepare_data(linear_data, random_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvAutogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
