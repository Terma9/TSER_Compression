{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.data_loader import load_from_tsfile_to_dataframe\n",
    "from utils.regressor_tools import process_data\n",
    "#import mlflow\n",
    "#from tsfeatures import tsfeatures\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "#pd.set_option('display.max_rows', None)  \n",
    "#pd.set_option('display.max_columns', None) \n",
    "from utils.personal_utils import *\n",
    "from compression import *\n",
    "from utils.compression_algos import *\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from flaml_and_fwiz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/07/13 17:30:08 INFO mlflow.tracking.fluent: Experiment with name 'Trash' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurewiz is given 0.9 as correlation limit...\n",
      "    Skipping feature engineering since no feature_engg input...\n",
      "    final list of category encoders given: ['label', 'label']\n",
      "    final list of scalers given: []\n",
      "Loaded input data. Shape = (42, 4368)\n",
      "#### Starting featurewiz transform for train data ####\n",
      "    Regression models don't need targets to be transformed to numeric...\n",
      "    Single_Label Regression problem \n",
      "Shape of dataset: (42, 4368). Now we classify variables into different types...\n",
      "Time taken to define data pipeline = 1 second(s)\n",
      "No model input given...\n",
      "Lazy Transformer Pipeline created...\n",
      "    Time taken to fit dataset = 1 second(s)\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (42, 4368)\n",
      "    Single_Label Regression problem \n",
      "Starting SULOV with 4102 features...\n",
      "    there are no null values in dataset...\n",
      "    there are no null values in target column...\n",
      "Completed SULOV. 1175 features selected\n",
      "Performing recursive XGBoost feature selection from 1175 features...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Run flaml for seeing output:\u001b[39;00m\n\u001b[1;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/sim/Desktop/TS Extrinsic Regression/data/prepared_data/AppliancesEnergy_TEST_ts_and_features.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mrun_flaml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTrash\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest RSME output\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m output\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/TSER Code/flaml_and_fwiz.py:46\u001b[0m, in \u001b[0;36mrun_flaml\u001b[0;34m(source_path_train, experiment_name, run_name, time)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#mlflow.set_experiment(\"IEEEPPG_Dataset\")\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m \n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# no activated feature engg, takes too long, feature_engg='interactions'\u001b[39;00m\n\u001b[1;32m     44\u001b[0m fwiz \u001b[38;5;241m=\u001b[39m FeatureWiz(transform_target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ) \u001b[38;5;66;03m# see other parameters on doc\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m train_data_fw , train_y_fw  \u001b[38;5;241m=\u001b[39m fwiz\u001b[38;5;241m.\u001b[39mfit_transform(train_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]), train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# apply same learned feature transformations on test data _-> nothing with current params??\u001b[39;00m\n\u001b[1;32m     49\u001b[0m test_data_fw \u001b[38;5;241m=\u001b[39m fwiz\u001b[38;5;241m.\u001b[39mtransform(test_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/featurewiz/featurewiz.py:3326\u001b[0m, in \u001b[0;36mFeatureWiz.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   3324\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m   3325\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m-> 3326\u001b[0m     X_sel, y_sel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X_sel, y_sel\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/featurewiz/featurewiz.py:3608\u001b[0m, in \u001b[0;36mFeatureWiz.transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   3606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_xgboost:\n\u001b[1;32m   3607\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPerforming recursive XGBoost feature selection from \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features...\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumvars))\n\u001b[0;32m-> 3608\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mFE_perform_recursive_xgboost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumvars\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   3609\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_label_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m   3610\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdask_xgboost_flag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3612\u001b[0m     features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumvars)\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/featurewiz/featurewiz.py:1427\u001b[0m, in \u001b[0;36mFE_perform_recursive_xgboost\u001b[0;34m(train, target, model_type, multi_label_type, dask_xgboost_flag, verbose)\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1425\u001b[0m     \u001b[38;5;66;03m#### now this training via bst works well for both xgboost 0.0.90 as well as 1.5.1 ##                        \u001b[39;00m\n\u001b[1;32m   1426\u001b[0m     dtrain \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_train, y_train, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, feature_names\u001b[38;5;241m=\u001b[39mcols_sel)\n\u001b[0;32m-> 1427\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m)\u001b[49m                \n\u001b[1;32m   1429\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error_msg:\n\u001b[1;32m   1431\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRegular XGBoost is crashing due to: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39merror_msg)\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/xgboost/core.py:575\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    574\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/xgboost/core.py:1778\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1782\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run flaml for seeing output: bevore that start the mlflow server on 5001\n",
    "path = '/home/sim/Desktop/TS Extrinsic Regression/data/prepared_data/AppliancesEnergy_TEST_ts_and_features.csv'\n",
    "output = run_flaml(path, 'Trash', 'Test RSME output', 5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and visualize the output from the run on the server and the compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/sim/Desktop/TS Extrinsic Regression/data/RegRSMEvsCompRatio/'\n",
    "data = np.load(path +'rsme_compRatio.npz')\n",
    "\n",
    "rmse_values = data['rmse_values']\n",
    "comp_ratios = data['comp_ratios']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/home/sim/Desktop/TS Extrinsic Regression/data/RegRSMEvsCompRatio/'\n",
    "data = np.load(path + 'rsme_compRatio.npz')\n",
    "\n",
    "rmse_values = data['rmse_values']\n",
    "comp_ratios = data['comp_ratios']\n",
    "comp_ratios = np.round(comp_ratios, 3)\n",
    "\n",
    "# Create the bar graph using index positions for x-axis\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(comp_ratios)), rmse_values, color='blue', width=0.5)\n",
    "plt.xlabel('Compression Ratios')\n",
    "plt.ylabel('RMSE Values')\n",
    "plt.title('Compression Ratio vs Regression-RMSE')\n",
    "plt.xticks(range(len(comp_ratios)), comp_ratios)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to see if the compression code still works properly\n",
    "What we should get:\n",
    "- Imcreasing RSME and Compression Ratio\n",
    "- RSME of dropout 0 should be nearly zero. RSME for dropout 1 should be around 1.\n",
    "- Compression Ratio should make sense! Super high for dropout_value close to 1. For droput_value around 0.8, 0.9 Ratio of 3 to 5.\n",
    "- dct has alredy good comp_ratio for i = 0.0 because of quantization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "216it [00:00, 10707.60it/s]\n",
      "100%|| 202/202 [00:00<00:00, 2448.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ FloodModeling1 +++\n",
      "$$$ dct $$$\n",
      "RMSE\n",
      "0.00  0.006274032499670094\n",
      "0.04  0.006935093895659105\n",
      "0.08  0.010768881666473358\n",
      "0.12  0.017199174444292864\n",
      "0.16  0.025577690263580678\n",
      "0.20  0.03515986466589614\n",
      "0.24  0.046214811460719575\n",
      "0.28  0.058080890740497576\n",
      "0.32  0.07127562721879624\n",
      "0.36  0.08560826743048223\n",
      "0.40  0.10067339209565142\n",
      "0.44  0.1172254492758263\n",
      "0.48  0.13450712789881258\n",
      "0.52  0.1534175933418722\n",
      "0.56  0.1732032121023388\n",
      "0.60  0.1950292134963751\n",
      "0.64  0.21815607297563913\n",
      "0.68  0.2437608938752914\n",
      "0.72  0.2718064225162032\n",
      "0.76  0.3023937676200057\n",
      "0.80  0.33854994453632614\n",
      "0.84  0.3811509600139657\n",
      "0.88  0.43660336054342097\n",
      "0.92  0.5131839530911695\n",
      "0.96  0.6386861417860717\n",
      "1.00  1.0\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  1.8424929036775832\n",
      "0.04  1.8516852238168247\n",
      "0.08  1.8737489985630174\n",
      "0.12  1.898079326025068\n",
      "0.16  1.930507697346872\n",
      "0.20  1.9722393253915138\n",
      "0.24  2.0161736132016093\n",
      "0.28  2.0696116300301988\n",
      "0.32  2.130478159656454\n",
      "0.36  2.20366714525006\n",
      "0.40  2.286703085231858\n",
      "0.44  2.387600667606501\n",
      "0.48  2.5026496365242203\n",
      "0.52  2.6449702017663532\n",
      "0.56  2.806911266049453\n",
      "0.60  3.0025267962668623\n",
      "0.64  3.2329734948218363\n",
      "0.68  3.531444732048701\n",
      "0.72  3.9053778260754326\n",
      "0.76  4.394714865187306\n",
      "0.80  5.0903751813722105\n",
      "0.84  6.070616348055372\n",
      "0.88  7.7023523261892315\n",
      "0.92  10.588243748203507\n",
      "0.96  18.26527829428536\n",
      "1.00  326.70953436807093\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$$ dft $$$\n",
      "RMSE\n",
      "0.00  2.857734973578324e-16\n",
      "0.04  0.013986743109718883\n",
      "0.08  0.028725878295214786\n",
      "0.12  0.04329213351596543\n",
      "0.16  0.058395570415908385\n",
      "0.20  0.07336628281260756\n",
      "0.24  0.08916893018209619\n",
      "0.28  0.1049883998518811\n",
      "0.32  0.1216204468706821\n",
      "0.36  0.13867447963865703\n",
      "0.40  0.15570284782610325\n",
      "0.44  0.17368418388381138\n",
      "0.48  0.19189277233769625\n",
      "0.52  0.21107407491446278\n",
      "0.56  0.23080267923047643\n",
      "0.60  0.252165563718357\n",
      "0.64  0.2741689014244427\n",
      "0.68  0.2976416056586894\n",
      "0.72  0.32389946985607393\n",
      "0.76  0.3534387273356437\n",
      "0.80  0.3886867258192765\n",
      "0.84  0.4310062543340196\n",
      "0.88  0.4886804819772916\n",
      "0.92  0.566390148960403\n",
      "0.96  0.6886659284674449\n",
      "1.00  1.0\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  0.500370151524413\n",
      "0.04  0.513259416397577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sim/Desktop/TS Extrinsic Regression/TSER Code/compression.py:111: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array_flatdim_coeff[:,i] = np.array(coeff_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08  0.5298214703079772\n",
      "0.12  0.5484111092087927\n",
      "0.16  0.5703281943697189\n",
      "0.20  0.5945182596906888\n",
      "0.24  0.6220805539137043\n",
      "0.28  0.6525335907814673\n",
      "0.32  0.6872641619440751\n",
      "0.36  0.7262645281493676\n",
      "0.40  0.7698569443138238\n",
      "0.44  0.8219635057262874\n",
      "0.48  0.8801242421527342\n",
      "0.52  0.9504231384488364\n",
      "0.56  1.031451912105451\n",
      "0.60  1.1319853110643332\n",
      "0.64  1.2504434166419145\n",
      "0.68  1.4007738451739251\n",
      "0.72  1.5991708180032342\n",
      "0.76  1.8544584985211756\n",
      "0.80  2.203733062127965\n",
      "0.84  2.717858855646143\n",
      "0.88  3.5846247415156305\n",
      "0.92  5.167134240426427\n",
      "0.96  9.538192646297256\n",
      "1.00  326.70953436807093\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$$ dwt $$$\n",
      "RMSE\n",
      "0.00  6.572596242129255e-16\n",
      "0.04  6.572596242129255e-16\n",
      "0.08  6.572596242129255e-16\n",
      "0.12  6.572596242129255e-16\n",
      "0.16  6.572596242129255e-16\n",
      "0.20  6.572596242129255e-16\n",
      "0.24  6.572596242129255e-16\n",
      "0.28  6.572596242129255e-16\n",
      "0.32  8.911307321641015e-06\n",
      "0.36  0.0001301479619372805\n",
      "0.40  0.0005014920125440056\n",
      "0.44  0.0012832018310334002\n",
      "0.48  0.0028365160436743114\n",
      "0.52  0.005190893872088812\n",
      "0.56  0.009027974092687758\n",
      "0.60  0.014911185786874632\n",
      "0.64  0.023036347738617964\n",
      "0.68  0.034772589611323984\n",
      "0.72  0.0503533743367567\n",
      "0.76  0.07163064180633531\n",
      "0.80  0.09939737717180963\n",
      "0.84  0.1346613470678784\n",
      "0.88  0.18349667506251308\n",
      "0.92  0.2586318370775126\n",
      "0.96  0.4023598002694402\n",
      "1.00  1.0\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  0.7285592084769312\n",
      "0.04  0.7285592084769312\n",
      "0.08  0.7285592084769312\n",
      "0.12  0.7285592084769312\n",
      "0.16  0.7285592084769312\n",
      "0.20  0.7285592084769312\n",
      "0.24  0.7285592084769312\n",
      "0.28  0.7285592084769312\n",
      "0.32  0.728916020262783\n",
      "0.36  0.7300970681359846\n",
      "0.40  0.7358580082602116\n",
      "0.44  0.7476835642157609\n",
      "0.48  0.7642427385892117\n",
      "0.52  0.7868146890302186\n",
      "0.56  0.8213541144073938\n",
      "0.60  0.8722517552064217\n",
      "0.64  0.9400363647963252\n",
      "0.68  1.0323769486775267\n",
      "0.72  1.1581710854169451\n",
      "0.76  1.3299335692107734\n",
      "0.80  1.5724622214633313\n",
      "0.84  1.9237025915529735\n",
      "0.88  2.5091701718236465\n",
      "0.92  3.645734362628662\n",
      "0.96  6.901451990632318\n",
      "1.00  324.55066079295153\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:01, 56.87it/s] \n",
      "100%|| 42/42 [00:00<00:00, 566.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ AppliancesEnergy +++\n",
      "$$$ dct $$$\n",
      "RMSE\n",
      "0.00  0.00640419263916621\n",
      "0.04  0.006409175324841004\n",
      "0.08  0.00663094586725514\n",
      "0.12  0.0074045921389583585\n",
      "0.16  0.008880953849950843\n",
      "0.20  0.01084628618474862\n",
      "0.24  0.01326502084415076\n",
      "0.28  0.01621357481896293\n",
      "0.32  0.019471185253031705\n",
      "0.36  0.02309876052735807\n",
      "0.40  0.027221807768175087\n",
      "0.44  0.03162035059920456\n",
      "0.48  0.036387637170388766\n",
      "0.52  0.041719065407272035\n",
      "0.56  0.04738455994277475\n",
      "0.60  0.0536230282038452\n",
      "0.64  0.06072920477657591\n",
      "0.68  0.06850644727212453\n",
      "0.72  0.07740721946698884\n",
      "0.76  0.08814803502339795\n",
      "0.80  0.10130865671866987\n",
      "0.84  0.11939142941826988\n",
      "0.88  0.14806464971819183\n",
      "0.92  0.1964391535014975\n",
      "0.96  0.29729375079702286\n",
      "1.00  0.9990079365079365\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  3.9482928515861353\n",
      "0.04  3.961602063000139\n",
      "0.08  3.9911168325828754\n",
      "0.12  4.031888288012617\n",
      "0.16  4.083235995232419\n",
      "0.20  4.151168708422698\n",
      "0.24  4.240839543462653\n",
      "0.28  4.339438733826072\n",
      "0.32  4.45706646891222\n",
      "0.36  4.58514240591038\n",
      "0.40  4.729627865559444\n",
      "0.44  4.895798499464094\n",
      "0.48  5.089221650288566\n",
      "0.52  5.32586339575123\n",
      "0.56  5.6039504355293825\n",
      "0.60  5.931308811690054\n",
      "0.64  6.348900564312123\n",
      "0.68  6.854686061867222\n",
      "0.72  7.488409456047739\n",
      "0.76  8.382683272976411\n",
      "0.80  9.590534979423868\n",
      "0.84  11.323389908939166\n",
      "0.88  14.099827139152982\n",
      "0.92  19.1414163989384\n",
      "0.96  32.39713461629391\n",
      "1.00  590.6612068965517\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$$ dft $$$\n",
      "RMSE\n",
      "0.00  4.716563769310973e-16\n",
      "0.04  0.004583315163733732\n",
      "0.08  0.008636672389426033\n",
      "0.12  0.01261045634831185\n",
      "0.16  0.01672391905651998\n",
      "0.20  0.020777521317342278\n",
      "0.24  0.02493819021983818\n",
      "0.28  0.029283085153301813\n",
      "0.32  0.03371476992329699\n",
      "0.36  0.03831300855543046\n",
      "0.40  0.04319567014836685\n",
      "0.44  0.048118693818055454\n",
      "0.48  0.053304094256427674\n",
      "0.52  0.05895233831774143\n",
      "0.56  0.06485000204346368\n",
      "0.60  0.07118150720683833\n",
      "0.64  0.07827151386715224\n",
      "0.68  0.08611328014478666\n",
      "0.72  0.09540474713736262\n",
      "0.76  0.10724159394519044\n",
      "0.80  0.12243007751530642\n",
      "0.84  0.14408143729081352\n",
      "0.88  0.1773871698027158\n",
      "0.92  0.2325578707293866\n",
      "0.96  0.3416909210225073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sim/Desktop/TS Extrinsic Regression/TSER Code/compression.py:111: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array_flatdim_coeff[:,i] = np.array(coeff_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00  0.9990079365079365\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  0.8529032097443782\n",
      "0.04  0.8752772100153295\n",
      "0.08  0.9028862917285465\n",
      "0.12  0.9349999112990056\n",
      "0.16  0.9722390529152258\n",
      "0.20  1.01328634408141\n",
      "0.24  1.0594017153486128\n",
      "0.28  1.1131424393810163\n",
      "0.32  1.1722155119023585\n",
      "0.36  1.2395379549895071\n",
      "0.40  1.3179583357377807\n",
      "0.44  1.407321216204281\n",
      "0.48  1.511448916654534\n",
      "0.52  1.6379016064257028\n",
      "0.56  1.7845214220601642\n",
      "0.60  1.9615880123220686\n",
      "0.64  2.180747893783678\n",
      "0.68  2.4542123361272297\n",
      "0.72  2.8051528538032287\n",
      "0.76  3.2907181142297275\n",
      "0.80  3.937288817377313\n",
      "0.84  4.891010586278527\n",
      "0.88  6.470309932574083\n",
      "0.92  9.412927599945048\n",
      "0.96  17.41876191686793\n",
      "1.00  590.6612068965517\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$$ dwt $$$\n",
      "RMSE\n",
      "0.00  5.040426526181978e-16\n",
      "0.04  5.9936185917228813e-05\n",
      "0.08  0.00022562168391515022\n",
      "0.12  0.0005065031573571895\n",
      "0.16  0.0009068448209922664\n",
      "0.20  0.00143585406301341\n",
      "0.24  0.0021136602076584562\n",
      "0.28  0.0029188745445709826\n",
      "0.32  0.003894882641346664\n",
      "0.36  0.0050639930089214965\n",
      "0.40  0.006413852699226404\n",
      "0.44  0.00799068190153901\n",
      "0.48  0.009879410603003113\n",
      "0.52  0.012008669145238193\n",
      "0.56  0.014591228719718088\n",
      "0.60  0.017593535240536886\n",
      "0.64  0.02122324578210963\n",
      "0.68  0.025833203600940973\n",
      "0.72  0.03158233727992173\n",
      "0.76  0.03929192331272111\n",
      "0.80  0.050581594666246836\n",
      "0.84  0.06751192962142669\n",
      "0.88  0.09564984593214898\n",
      "0.92  0.15016313644217363\n",
      "0.96  0.2745041232561796\n",
      "1.00  0.9990079365079365\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  0.6557218120307587\n",
      "0.04  0.6673916897355825\n",
      "0.08  0.6853040608121624\n",
      "0.12  0.7080226801375192\n",
      "0.16  0.7338310029613841\n",
      "0.20  0.7639262706516431\n",
      "0.24  0.7982084878393161\n",
      "0.28  0.8359467076607737\n",
      "0.32  0.8784192307692308\n",
      "0.36  0.9277455590775717\n",
      "0.40  0.9828960392488775\n",
      "0.44  1.0460516974731413\n",
      "0.48  1.120953281547553\n",
      "0.52  1.206815347654241\n",
      "0.56  1.3108301750344846\n",
      "0.60  1.4336497055980315\n",
      "0.64  1.5828104786545925\n",
      "0.68  1.7746164784132321\n",
      "0.72  2.0144682952931734\n",
      "0.76  2.333349225755259\n",
      "0.80  2.7859338532475664\n",
      "0.84  3.4392135406732187\n",
      "0.88  4.495669461832211\n",
      "0.92  6.607203471552555\n",
      "0.96  12.481182599825123\n",
      "1.00  590.1524547803617\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5072it [00:11, 453.67it/s]\n",
      "100%|| 5048/5048 [00:05<00:00, 956.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ BeijingPM25Quality +++\n",
      "$$$ dct $$$\n",
      "RMSE\n",
      "0.00  0.006296655226801784\n",
      "0.04  0.006767491197033571\n",
      "0.08  0.009779098648530462\n",
      "0.12  0.015174618387245507\n",
      "0.16  0.022436521356719908\n",
      "0.20  0.030842558023504028\n",
      "0.24  0.04036997033062279\n",
      "0.28  0.05118556973264827\n",
      "0.32  0.06273464099704099\n",
      "0.36  0.07526279945574325\n",
      "0.40  0.08908632733425607\n",
      "0.44  0.1035837257241737\n",
      "0.48  0.11916205385264451\n",
      "0.52  0.1363012633924039\n",
      "0.56  0.15422719821634923\n",
      "0.60  0.1734595226762815\n",
      "0.64  0.1947504823889541\n",
      "0.68  0.21730982158413797\n",
      "0.72  0.24200346925785005\n",
      "0.76  0.270243568445171\n",
      "0.80  0.3017254963179742\n",
      "0.84  0.3389340440091282\n",
      "0.88  0.38641056722499406\n",
      "0.92  0.44866441319583866\n",
      "0.96  0.5428084649958498\n",
      "1.00  0.8947437929212063\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  3.610917276454746\n",
      "0.04  3.6256204589715284\n",
      "0.08  3.661167796305123\n",
      "0.12  3.711906039810898\n",
      "0.16  3.7759993690199685\n",
      "0.20  3.849015960322367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_compression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/TSER Code/utils/personal_utils.py:122\u001b[0m, in \u001b[0;36mtest_compression\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.04\u001b[39m, \u001b[38;5;241m0.04\u001b[39m):\n\u001b[1;32m    121\u001b[0m     decompressed_dataset \u001b[38;5;241m=\u001b[39m compress_dataset(dataset_array\u001b[38;5;241m.\u001b[39mcopy(), dataset_id, \u001b[38;5;28;01mFalse\u001b[39;00m, comp_tq, i) \n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcalculateCompRatio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_array\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mdecompressed_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/TSER Code/compression.py:150\u001b[0m, in \u001b[0;36mcalculateCompRatio\u001b[0;34m(dataset_array, array_flatdim_comp)\u001b[0m\n\u001b[1;32m    146\u001b[0m compressed_data_bytestring \u001b[38;5;241m=\u001b[39m array_flatdim_1d\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Compress the byte-string with gzip. -> Input is byte string and then returns a byte-string. ->> Test more by yourself!\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m compressed_data_gzipd \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompressed_data_bytestring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# .nbytes simply returns: np.prod(a.shape) * a.itemsize -> simply how many bytes are filled in the array. No metadata. Only counts the byte of the elements.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m num_bytes_raw \u001b[38;5;241m=\u001b[39m dataset_array\u001b[38;5;241m.\u001b[39mnbytes\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:549\u001b[0m, in \u001b[0;36mcompress\u001b[0;34m(data, compresslevel, mtime)\u001b[0m\n\u001b[1;32m    547\u001b[0m buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m GzipFile(fileobj\u001b[38;5;241m=\u001b[39mbuf, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, compresslevel\u001b[38;5;241m=\u001b[39mcompresslevel, mtime\u001b[38;5;241m=\u001b[39mmtime) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 549\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:289\u001b[0m, in \u001b[0;36mGzipFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    286\u001b[0m     length \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnbytes\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcrc32(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_compression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:01, 62.48it/s] \n",
      "100%|| 42/42 [00:00<00:00, 642.88it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/sim/Desktop/TS Extrinsic Regression/data/AppliancesEnergy_TEST.ts\"\n",
    "dataset_array = load_dataset(data_path)\n",
    "dataset_id = os.path.basename(data_path).split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0   5.040426526181978e-16\n",
      "0.1   0.0003464869636634713\n",
      "0.2   0.00143585406301341\n",
      "0.30000000000000004   0.0033854854425775997\n",
      "0.4   0.006413852699226404\n",
      "0.5   0.010901034462780138\n",
      "0.6000000000000001   0.017593535240536886\n",
      "0.7000000000000001   0.02851264206464209\n",
      "0.8   0.050581594666246836\n",
      "0.9   0.11883603009165886\n",
      "1.0   0.9990079365079365\n"
     ]
    }
   ],
   "source": [
    "# Check if RMSE increases with increasing dropout_ratio\n",
    "for i in np.arange(0, 1.04, 0.1):\n",
    "    decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, True, \"dwt\", i) \n",
    "    print(i, \" \" ,compute_avg_rmse_of_dataset(dataset_array, decompressed_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6557218120307587\n",
      "0.695904811237393\n",
      "0.7639262706516431\n",
      "0.8564384095877723\n",
      "0.9828960392488775\n",
      "1.16226921432788\n",
      "1.4336497055980315\n",
      "1.8868002985099288\n",
      "2.7859338532475664\n",
      "5.364644258097855\n"
     ]
    }
   ],
   "source": [
    "# Check that Compression Ratio increases with increasing dropout_ratio\n",
    "for i in np.arange(0, 1, 0.1):\n",
    "    decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, False, \"dwt\", i) \n",
    "    print(calculateCompRatio(dataset_array, decompressed_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23]\n",
      "  [24 25 26 27]\n",
      "  [28 29 30 31]\n",
      "  [32 33 34 35]\n",
      "  [36 37 38 39]]]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]\n",
      " [24 25 26 27]\n",
      " [28 29 30 31]\n",
      " [32 33 34 35]\n",
      " [36 37 38 39]]\n",
      "[ 0  4  8 12 16 20 24 28 32 36  1  5  9 13 17 21 25 29 33 37  2  6 10 14\n",
      " 18 22 26 30 34 38  3  7 11 15 19 23 27 31 35 39]\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23]\n",
      "  [24 25 26 27]\n",
      "  [28 29 30 31]\n",
      "  [32 33 34 35]\n",
      "  [36 37 38 39]]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "# Test if reshaping from (len_flat_dim, dim) to (num_dp, len_ts, dim) is working\n",
    "num_dp = 2\n",
    "len_ts = 5\n",
    "num_dim = 4\n",
    "\n",
    "array = np.arange(num_dp * len_ts * num_dim).reshape(num_dp, len_ts, num_dim)\n",
    "print(array)\n",
    "\n",
    "# Reshape to (len_flat_dim, dim)\n",
    "array_flatdim = array.reshape(num_dp * len_ts, num_dim)\n",
    "print(array_flatdim)\n",
    "\n",
    "# Put column after column. For gzip part.\n",
    "print(array_flatdim.reshape(-1, order='F'))\n",
    "\n",
    "\n",
    "# Reshape back to (num_dp, len_ts, dim)\n",
    "array_back = array_flatdim.reshape(-1, len_ts, num_dim)\n",
    "print(array_back)\n",
    "\n",
    "print(array_back.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "int64\n",
      "<class 'bytearray'>\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Test binary conversion and compression\n",
    "num_dp = 2\n",
    "len_ts = 2\n",
    "num_dim = 2\n",
    "\n",
    "array = np.arange(num_dp * len_ts * num_dim).reshape(num_dp, len_ts, num_dim)\n",
    "array_flat = array.reshape(num_dp * len_ts, num_dim)\n",
    "\n",
    "# Test if .tobytes saves metadata of the np.array -> No it flattens the array row after row (and slice after slice), then just saves the content of the array as bytes!\n",
    "print(array_flat.tobytes() == np.arange(8).tobytes())\n",
    "\n",
    "\n",
    "byte_nparray = np.arange(5)\n",
    "print(byte_nparray.dtype)\n",
    "\n",
    "byte_nparray = byte_nparray.tobytes()\n",
    "\n",
    "print(bytearray)\n",
    "print(len(byte_nparray))\n",
    "\n",
    "# len(byte-string) -> return number of bytes in byte-object!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if saving with tofile keeps the array the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test Saving in Files\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_series.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtrain_x_p\u001b[49m)\n\u001b[1;32m      4\u001b[0m train_x_p[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m      7\u001b[0m flattened \u001b[38;5;241m=\u001b[39m train_x_p\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_p' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Saving in Files\n",
    "\n",
    "np.save('time_series.npy', train_x_p)\n",
    "train_x_p[0][0][0].dtype\n",
    "\n",
    "\n",
    "flattened = train_x_p.flatten()\n",
    "flattened.tofile(\"data.bin\")\n",
    "\n",
    "train_after = np.fromfile(\"data.bin\", dtype=train_x_p[0][0][0].dtype)\n",
    "train_after.shape\n",
    "if np.array_equal(flattened, train_after):\n",
    "    print(\"The arrays have the same content.\")\n",
    "else:\n",
    "    print(\"The arrays do not have the same content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only preparing Data for Testing!\n",
    "\n",
    "def prepare_data(data_x_p, data_y):\n",
    "\n",
    "    # Swap the dimensions so that columns are stacked after each other. Copy since swapaxes only returns a view\n",
    "    #(95, 144, 24) -> (95, 24, 144), first column gets first row etc. One Row is the ts of the belonging dimension.\n",
    "    data_swapped = data_x_p.swapaxes(1, 2).copy()\n",
    "\n",
    "    # Reshape to flattened ts. Stack the rows behind the other for each slice.\n",
    "    data_x_flattend = data_swapped.reshape(data_swapped.shape[0], -1)\n",
    "    \n",
    "\n",
    "    prep_data = pd.DataFrame(data_x_flattend)\n",
    "    prep_data['target'] = data_y\n",
    "    prep_data.columns = prep_data.columns.astype(str) #fwiz or flaml needs string as columns!\n",
    "\n",
    "   \n",
    "    #data_x_p = data_x_p[0:2,...]\n",
    "\n",
    "    num_datapoints = data_x_p.shape[0]\n",
    "    len_timeseries = data_x_p.shape[1]\n",
    "    num_dimensions = data_x_p.shape[2]\n",
    "    num_features = 38\n",
    "\n",
    "    all_features = np.ndarray((num_datapoints, num_features * num_dimensions))\n",
    "\n",
    "    for i in range(0, num_datapoints):\n",
    "        start_index = 0\n",
    "\n",
    "        for j in range(0, num_dimensions):\n",
    "            curr_ts = data_x_p[i,:,j]\n",
    "\n",
    "            #print(curr_ts.size)\n",
    "\n",
    "            timeseries_df = pd.DataFrame({'unique_id' : np.ones(len_timeseries),'ds': np.arange(0, len_timeseries) , 'y': curr_ts})\n",
    "            \n",
    "            feature_array = tsfeatures(timeseries_df, freq=1).fillna(0).values\n",
    "\n",
    "            #print(feature_array.size)\n",
    "            #print(np.isnan(feature_array).sum())\n",
    "\n",
    "            end_index = start_index + feature_array.size\n",
    "            all_features[i, start_index: end_index] = feature_array\n",
    "            start_index = end_index\n",
    "        \n",
    "\n",
    "    all_features = pd.DataFrame(all_features)\n",
    "\n",
    "    # name the features\n",
    "    for i, col in enumerate(all_features.columns):\n",
    "        # Generate the new column name\n",
    "        new_col_name = 'f' + str(i + 1)\n",
    "        # Rename the column\n",
    "        all_features.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ts_and_features = pd.concat([prep_data, all_features], axis=1)\n",
    "\n",
    "\n",
    "    all_features['target'] = data_y\n",
    "\n",
    "    ts_and_features = pd.concat([prep_data.drop(columns=['target']), all_features], axis=1)\n",
    "    \n",
    "    #prep_data.columns = prep_data.columns.astype(str)\n",
    "\n",
    "    return ts_and_features, all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test preparing part function of load_and_prepare_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00000000e+00  3.74540119e-01]\n",
      "  [ 1.00000000e+00  9.50714306e-01]\n",
      "  [ 2.00000000e+00  7.31993942e-01]]\n",
      "\n",
      " [[ 0.00000000e+00  7.49080238e-02]\n",
      "  [ 1.22464680e-16  1.19014286e+00]\n",
      "  [-2.44929360e-16  2.14639879e+00]]]\n",
      "[[ 1.00000000e+00  5.00000000e-01  3.00000000e+00  4.44089210e-16\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.35200499e+02  0.00000000e+00  9.99999985e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  6.66801831e-01  3.00000000e+00 -2.75921612e+00\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.15119426e+02  0.00000000e+00  1.49011612e-08  1.47344817e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  2.00000000e+00  0.00000000e+00\n",
      "  -4.14940655e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  7.15004181e-01  3.00000000e+00 -8.00000000e+00\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.41667483e+02  0.00000000e+00  1.49011613e-08  1.47776810e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.26435418e-31  2.00000000e+00  0.00000000e+00\n",
      "  -3.80952381e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  5.59880864e-01  3.00000000e+00 -2.85103917e-01\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   6.95053958e+02  0.00000000e+00  1.49011612e-08  1.22257941e-11\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  8.75840729e-31  1.00000000e+00  0.00000000e+00\n",
      "  -1.30631734e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "     0             1             2         3         4         5   f1  \\\n",
      "0  0.0  1.000000e+00  2.000000e+00  0.374540  0.950714  0.731994  1.0   \n",
      "1  0.0  1.224647e-16 -2.449294e-16  0.074908  1.190143  2.146399  1.0   \n",
      "\n",
      "         f2   f3            f4  ...           f68  f69  f70       f71  f72  \\\n",
      "0  0.500000  3.0  4.440892e-16  ... -0.000000e+00  2.0  0.0 -0.414941  0.0   \n",
      "1  0.715004  3.0 -8.000000e+00  ...  8.758407e-31  1.0  0.0 -0.001306  0.0   \n",
      "\n",
      "   f73  f74  f75  f76  target  \n",
      "0  0.0  0.0  0.0  0.0       0  \n",
      "1  0.0  0.0  0.0  0.0       1  \n",
      "\n",
      "[2 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "# Simple test:\n",
    "#-> No a perfect test, but it seems to work! I have no idea about better tests!\n",
    "\n",
    "len_ts = 3\n",
    "ts_1_v = np.arange(len_ts)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "ts_2_v = np.random.rand(len_ts)\n",
    "x = np.linspace(0, 2 * np.pi, len_ts)\n",
    "ts_3_v = np.sin(x)\n",
    "\n",
    "ts_4_v =  ts_1_v + 0.2 * ts_2_v\n",
    "\n",
    "\n",
    "# Reulting Feature matrix\n",
    "ts_1 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_1_v})\n",
    "ts_2 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_2_v})\n",
    "ts_3 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_3_v})\n",
    "ts_4 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_4_v})\n",
    "\n",
    "feature_matrix = np.vstack((tsfeatures(ts_1, freq=1).fillna(0).values, tsfeatures(ts_2, freq=1).fillna(0).values, tsfeatures(ts_3, freq=1).fillna(0).values,tsfeatures(ts_4, freq=1).fillna(0).values))\n",
    "#print(feature_matrix)\n",
    "\n",
    "\n",
    "layer1 = np.stack((ts_1_v, ts_2_v), axis=1)\n",
    "layer2 = np.stack((ts_3_v,ts_4_v), axis=1)\n",
    "\n",
    "input = np.stack((layer1, layer2), axis=0)\n",
    "\n",
    "\n",
    "print(input)\n",
    "print(feature_matrix)\n",
    "tsf, f = prepare_data(input, np.arange(2))\n",
    "print(tsf)\n",
    "#print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1    2    3    4    5    6    7    8    9  ...      f144  f145  \\\n",
       " 0    0    4    8   12   16   20   24   28   32   36  ...  0.521199   1.0   \n",
       " 1  120  124  128  132  136  140  144  148  152  156  ...  0.521199   1.0   \n",
       " 2  240  244  248  252  256  260  264  268  272  276  ...  0.521199   1.0   \n",
       " \n",
       "    f146  f147      f148      f149      f150      f151     f152    target  \n",
       " 0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.388170  \n",
       " 1   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.643288  \n",
       " 2   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.458253  \n",
       " \n",
       " [3 rows x 273 columns],\n",
       "     f1        f2    f3   f4        f5   f6   f7   f8        f9  f10  ...  \\\n",
       " 0  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " 1  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " 2  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " \n",
       "        f144  f145  f146  f147      f148      f149      f150      f151  \\\n",
       " 0  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " 1  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " 2  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " \n",
       "       f152    target  \n",
       " 0  0.53624  0.388170  \n",
       " 1  0.53624  0.643288  \n",
       " 2  0.53624  0.458253  \n",
       " \n",
       " [3 rows x 153 columns])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Sample TS\n",
    "linear_data = linear_data = np.arange(360).reshape(3, 30, 4)  # Creates an array with values from 0 to 1199\n",
    "linear_data\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "random_data = np.random.rand(3, 30, 4)\n",
    "random_y = np.random.rand(3)\n",
    "random_data\n",
    "\n",
    "prepare_data(linear_data, random_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvAutogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
