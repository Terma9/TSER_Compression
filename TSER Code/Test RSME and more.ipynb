{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.data_loader import load_from_tsfile_to_dataframe\n",
    "from utils.regressor_tools import process_data\n",
    "#import mlflow\n",
    "#from tsfeatures import tsfeatures\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "#pd.set_option('display.max_rows', None)  \n",
    "#pd.set_option('display.max_columns', None) \n",
    "from utils.personal_utils import *\n",
    "from compression import *\n",
    "from utils.compression_algos import *\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from flaml_and_fwiz import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "featurewiz is given 0.9 as correlation limit...\n",
      "    Skipping feature engineering since no feature_engg input...\n",
      "    final list of category encoders given: ['label', 'label']\n",
      "    final list of scalers given: []\n",
      "Loaded input data. Shape = (42, 4368)\n",
      "#### Starting featurewiz transform for train data ####\n",
      "    Regression models don't need targets to be transformed to numeric...\n",
      "    Single_Label Regression problem \n",
      "Shape of dataset: (42, 4368). Now we classify variables into different types...\n",
      "Time taken to define data pipeline = 1 second(s)\n",
      "No model input given...\n",
      "Lazy Transformer Pipeline created...\n",
      "    Time taken to fit dataset = 1 second(s)\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (42, 4368)\n",
      "    Single_Label Regression problem \n",
      "Starting SULOV with 4102 features...\n",
      "    there are no null values in dataset...\n",
      "    there are no null values in target column...\n",
      "Completed SULOV. 1175 features selected\n",
      "Performing recursive XGBoost feature selection from 1175 features...\n",
      "    time taken to run entire featurewiz = 30 second(s)\n",
      "Recursive XGBoost selected 462 features...\n",
      "#### Starting featurewiz transform for test data ####\n",
      "Loaded input data. Shape = (42, 4368)\n",
      "#### Starting lazytransform for test data ####\n",
      "    Time taken to transform dataset = 1 second(s)\n",
      "    Shape of transformed dataset: (42, 4368)\n",
      "Returning dataframe with 462 features \n",
      "[flaml.automl.logger: 07-13 15:35:56] {1680} INFO - task = regression\n",
      "[flaml.automl.logger: 07-13 15:35:56] {1691} INFO - Evaluation method: holdout\n",
      "[flaml.automl.logger: 07-13 15:35:56] {1789} INFO - Minimizing error metric: rmse\n",
      "[flaml.automl.logger: 07-13 15:35:56] {1901} INFO - List of ML learners in AutoML Run: ['lgbm', 'rf', 'xgboost', 'extra_tree', 'xgb_limitdepth']\n",
      "[flaml.automl.logger: 07-13 15:35:56] {2219} INFO - iteration 0, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 15:35:56] {2345} INFO - Estimated sufficient time budget=85s. Estimated necessary time budget=1s.\n",
      "[flaml.automl.logger: 07-13 15:35:56] {2392} INFO -  at 0.1s,\testimator lgbm's best error=2.4110,\tbest estimator lgbm's best error=2.4110\n",
      "[flaml.automl.logger: 07-13 15:35:56] {2219} INFO - iteration 1, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 15:35:56] {2392} INFO -  at 0.3s,\testimator lgbm's best error=2.4110,\tbest estimator lgbm's best error=2.4110\n",
      "[flaml.automl.logger: 07-13 15:35:56] {2219} INFO - iteration 2, current learner xgboost\n",
      "[flaml.automl.logger: 07-13 15:35:56] {2392} INFO -  at 0.3s,\testimator xgboost's best error=7.6242,\tbest estimator lgbm's best error=2.4110\n",
      "[flaml.automl.logger: 07-13 15:35:56] {2219} INFO - iteration 3, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 0.4s,\testimator extra_tree's best error=1.7052,\tbest estimator extra_tree's best error=1.7052\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 4, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 0.4s,\testimator rf's best error=1.7485,\tbest estimator extra_tree's best error=1.7052\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 5, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 0.5s,\testimator extra_tree's best error=1.5569,\tbest estimator extra_tree's best error=1.5569\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 6, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 0.9s,\testimator lgbm's best error=1.5489,\tbest estimator lgbm's best error=1.5489\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 7, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 0.9s,\testimator rf's best error=1.7485,\tbest estimator lgbm's best error=1.5489\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 8, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 1.0s,\testimator rf's best error=1.7485,\tbest estimator lgbm's best error=1.5489\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 9, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 1.1s,\testimator rf's best error=1.7485,\tbest estimator lgbm's best error=1.5489\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 10, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 1.1s,\testimator rf's best error=1.3636,\tbest estimator rf's best error=1.3636\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 11, current learner xgboost\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2392} INFO -  at 1.4s,\testimator xgboost's best error=7.6242,\tbest estimator rf's best error=1.3636\n",
      "[flaml.automl.logger: 07-13 15:35:57] {2219} INFO - iteration 12, current learner xgboost\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2392} INFO -  at 1.5s,\testimator xgboost's best error=1.9652,\tbest estimator rf's best error=1.3636\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2219} INFO - iteration 13, current learner xgboost\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2392} INFO -  at 1.8s,\testimator xgboost's best error=1.9652,\tbest estimator rf's best error=1.3636\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2219} INFO - iteration 14, current learner xgboost\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2392} INFO -  at 1.9s,\testimator xgboost's best error=1.9652,\tbest estimator rf's best error=1.3636\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2219} INFO - iteration 15, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2392} INFO -  at 2.0s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2219} INFO - iteration 16, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2392} INFO -  at 2.1s,\testimator rf's best error=1.3636,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2219} INFO - iteration 17, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2392} INFO -  at 2.1s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2219} INFO - iteration 18, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2392} INFO -  at 2.2s,\testimator lgbm's best error=1.5489,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2219} INFO - iteration 19, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2392} INFO -  at 2.2s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:58] {2219} INFO - iteration 20, current learner xgboost\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 2.4s,\testimator xgboost's best error=1.9652,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 21, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 2.5s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 22, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 2.8s,\testimator lgbm's best error=1.5489,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 23, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 2.9s,\testimator rf's best error=1.3636,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 24, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 3.0s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 25, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 3.1s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 26, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 3.1s,\testimator rf's best error=1.3636,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 27, current learner xgboost\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 3.3s,\testimator xgboost's best error=1.9652,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 28, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2392} INFO -  at 3.3s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:35:59] {2219} INFO - iteration 29, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 3.4s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 30, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 4.0s,\testimator lgbm's best error=1.5489,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 31, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 4.0s,\testimator lgbm's best error=1.5489,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 32, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 4.1s,\testimator rf's best error=1.3636,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 33, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 4.1s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 34, current learner lgbm\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 4.2s,\testimator lgbm's best error=1.5489,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 35, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 4.3s,\testimator rf's best error=1.3636,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 36, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 4.3s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 37, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2392} INFO -  at 4.4s,\testimator rf's best error=1.3636,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:00] {2219} INFO - iteration 38, current learner xgboost\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2392} INFO -  at 4.7s,\testimator xgboost's best error=1.9652,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2219} INFO - iteration 39, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2392} INFO -  at 4.8s,\testimator rf's best error=1.3636,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2219} INFO - iteration 40, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2392} INFO -  at 4.8s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2219} INFO - iteration 41, current learner extra_tree\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2392} INFO -  at 4.9s,\testimator extra_tree's best error=1.3094,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2219} INFO - iteration 42, current learner rf\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2392} INFO -  at 5.0s,\testimator rf's best error=1.3636,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2219} INFO - iteration 43, current learner xgb_limitdepth\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2392} INFO -  at 5.1s,\testimator xgb_limitdepth's best error=8.1588,\tbest estimator extra_tree's best error=1.3094\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2628} INFO - retrain extra_tree for 0.0s\n",
      "[flaml.automl.logger: 07-13 15:36:01] {2631} INFO - retrained model: ExtraTreesRegressor(max_features=0.9999999999999999, max_leaf_nodes=4,\n",
      "                    n_estimators=4, n_jobs=-1, random_state=12032022)\n",
      "[flaml.automl.logger: 07-13 15:36:01] {1931} INFO - fit succeeded\n",
      "[flaml.automl.logger: 07-13 15:36:01] {1932} INFO - Time taken to find the best model: 1.9856188297271729\n",
      "RMSE: 1.4960939504186033\n",
      "Mean Absolute Error: 1.2279986110380847\n",
      "R-squared Score: 0.8106711862419196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.4960939504186033"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run flaml for seeing output:\n",
    "path = '/home/sim/Desktop/TS Extrinsic Regression/data/prepared_data/AppliancesEnergy_TEST_ts_and_features.csv'\n",
    "output = run_flaml(path, 'Trash', 'Test RSME output', 5)\n",
    "output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)\n",
    "type(np.array([1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and visualize the output from the run on the server and the compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/sim/Desktop/TS Extrinsic Regression/data/RegRSMEvsCompRatio/'\n",
    "data = np.load(path +'rsme_compRatio.npz')\n",
    "\n",
    "rmse_values = data['rmse_values']\n",
    "comp_ratios = data['comp_ratios']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5,) and arg 1 with shape (0,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Create the bar graph\u001b[39;00m\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 10\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomp_ratios\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrmse_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mblue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCompression Ratios\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRMSE Values\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/matplotlib/pyplot.py:2754\u001b[0m, in \u001b[0;36mbar\u001b[0;34m(x, height, width, bottom, align, data, **kwargs)\u001b[0m\n\u001b[1;32m   2743\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mbar)\n\u001b[1;32m   2744\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbar\u001b[39m(\n\u001b[1;32m   2745\u001b[0m     x: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2752\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2753\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarContainer:\n\u001b[0;32m-> 2754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbottom\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbottom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2759\u001b[0m \u001b[43m        \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2760\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2761\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2762\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/matplotlib/__init__.py:1465\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1463\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1464\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1465\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1467\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1468\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1469\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/matplotlib/axes/_axes.py:2461\u001b[0m, in \u001b[0;36mAxes.bar\u001b[0;34m(self, x, height, width, bottom, align, **kwargs)\u001b[0m\n\u001b[1;32m   2458\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m yerr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2459\u001b[0m         yerr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_dx(yerr, y0, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_yunits)\n\u001b[0;32m-> 2461\u001b[0m x, height, width, y, linewidth, hatch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2462\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Make args iterable too.\u001b[39;49;00m\n\u001b[1;32m   2463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matleast_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2465\u001b[0m \u001b[38;5;66;03m# Now that units have been converted, set the tick locations.\u001b[39;00m\n\u001b[1;32m   2466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orientation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvertical\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/lib/stride_tricks.py:540\u001b[0m, in \u001b[0;36mbroadcast_arrays\u001b[0;34m(subok, *args)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m# nditer is not used here to avoid the limit of 32 arrays.\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Otherwise, something like the following one-liner would suffice:\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# return np.nditer(args, flags=['multi_index', 'zerosize_ok'],\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m#                  order='C').itviews\u001b[39;00m\n\u001b[1;32m    538\u001b[0m args \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marray(_m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, subok\u001b[38;5;241m=\u001b[39msubok) \u001b[38;5;28;01mfor\u001b[39;00m _m \u001b[38;5;129;01min\u001b[39;00m args]\n\u001b[0;32m--> 540\u001b[0m shape \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(array\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m shape \u001b[38;5;28;01mfor\u001b[39;00m array \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;66;03m# Common case where nothing needs to be broadcasted.\u001b[39;00m\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvAutogluon/lib/python3.10/site-packages/numpy/lib/stride_tricks.py:422\u001b[0m, in \u001b[0;36m_broadcast_shape\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the shape of the arrays that would result from broadcasting the\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;124;03msupplied arrays against each other.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# use the old-iterator because np.nditer does not handle size 0 arrays\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;66;03m# consistently\u001b[39;00m\n\u001b[0;32m--> 422\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbroadcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# unfortunately, it cannot handle 32 or more arguments directly\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;28mlen\u001b[39m(args), \u001b[38;5;241m31\u001b[39m):\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;66;03m# ironically, np.broadcast does not properly handle np.broadcast\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[38;5;66;03m# objects (it treats them as scalars)\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;66;03m# use broadcasting to avoid allocating the full array\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: shape mismatch: objects cannot be broadcast to a single shape.  Mismatch is between arg 0 with shape (5,) and arg 1 with shape (0,)."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = '/home/sim/Desktop/TS Extrinsic Regression/data/RegRSMEvsCompRatio/'\n",
    "data = np.load(path +'rsme_compRatio.npz')\n",
    "\n",
    "rmse_values = data['rmse_values']\n",
    "comp_ratios = data['comp_ratios']\n",
    "\n",
    "\n",
    "# Create the bar graph\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(comp_ratios, rmse_values, color='blue')\n",
    "plt.xlabel('Compression Ratios')\n",
    "plt.ylabel('RMSE Values')\n",
    "plt.title('Compression Ratios vs RMSE')\n",
    "plt.xticks(comp_ratios, rotation=45)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to see if the compression code still works properly\n",
    "What we should get:\n",
    "- Imcreasing RSME and Compression Ratio\n",
    "- RSME of dropout 0 should be nearly zero. RSME for dropout 1 should be around 1.\n",
    "- Compression Ratio should make sense! Super high for dropout_value close to 1. For droput_value around 0.8, 0.9 Ratio of 3 to 5.\n",
    "- dct has alredy good comp_ratio for i = 0.0 because of quantization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "216it [00:00, 10707.60it/s]\n",
      "100%|██████████| 202/202 [00:00<00:00, 2448.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ FloodModeling1 +++\n",
      "$$$ dct $$$\n",
      "RMSE\n",
      "0.00  0.006274032499670094\n",
      "0.04  0.006935093895659105\n",
      "0.08  0.010768881666473358\n",
      "0.12  0.017199174444292864\n",
      "0.16  0.025577690263580678\n",
      "0.20  0.03515986466589614\n",
      "0.24  0.046214811460719575\n",
      "0.28  0.058080890740497576\n",
      "0.32  0.07127562721879624\n",
      "0.36  0.08560826743048223\n",
      "0.40  0.10067339209565142\n",
      "0.44  0.1172254492758263\n",
      "0.48  0.13450712789881258\n",
      "0.52  0.1534175933418722\n",
      "0.56  0.1732032121023388\n",
      "0.60  0.1950292134963751\n",
      "0.64  0.21815607297563913\n",
      "0.68  0.2437608938752914\n",
      "0.72  0.2718064225162032\n",
      "0.76  0.3023937676200057\n",
      "0.80  0.33854994453632614\n",
      "0.84  0.3811509600139657\n",
      "0.88  0.43660336054342097\n",
      "0.92  0.5131839530911695\n",
      "0.96  0.6386861417860717\n",
      "1.00  1.0\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  1.8424929036775832\n",
      "0.04  1.8516852238168247\n",
      "0.08  1.8737489985630174\n",
      "0.12  1.898079326025068\n",
      "0.16  1.930507697346872\n",
      "0.20  1.9722393253915138\n",
      "0.24  2.0161736132016093\n",
      "0.28  2.0696116300301988\n",
      "0.32  2.130478159656454\n",
      "0.36  2.20366714525006\n",
      "0.40  2.286703085231858\n",
      "0.44  2.387600667606501\n",
      "0.48  2.5026496365242203\n",
      "0.52  2.6449702017663532\n",
      "0.56  2.806911266049453\n",
      "0.60  3.0025267962668623\n",
      "0.64  3.2329734948218363\n",
      "0.68  3.531444732048701\n",
      "0.72  3.9053778260754326\n",
      "0.76  4.394714865187306\n",
      "0.80  5.0903751813722105\n",
      "0.84  6.070616348055372\n",
      "0.88  7.7023523261892315\n",
      "0.92  10.588243748203507\n",
      "0.96  18.26527829428536\n",
      "1.00  326.70953436807093\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$$ dft $$$\n",
      "RMSE\n",
      "0.00  2.857734973578324e-16\n",
      "0.04  0.013986743109718883\n",
      "0.08  0.028725878295214786\n",
      "0.12  0.04329213351596543\n",
      "0.16  0.058395570415908385\n",
      "0.20  0.07336628281260756\n",
      "0.24  0.08916893018209619\n",
      "0.28  0.1049883998518811\n",
      "0.32  0.1216204468706821\n",
      "0.36  0.13867447963865703\n",
      "0.40  0.15570284782610325\n",
      "0.44  0.17368418388381138\n",
      "0.48  0.19189277233769625\n",
      "0.52  0.21107407491446278\n",
      "0.56  0.23080267923047643\n",
      "0.60  0.252165563718357\n",
      "0.64  0.2741689014244427\n",
      "0.68  0.2976416056586894\n",
      "0.72  0.32389946985607393\n",
      "0.76  0.3534387273356437\n",
      "0.80  0.3886867258192765\n",
      "0.84  0.4310062543340196\n",
      "0.88  0.4886804819772916\n",
      "0.92  0.566390148960403\n",
      "0.96  0.6886659284674449\n",
      "1.00  1.0\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  0.500370151524413\n",
      "0.04  0.513259416397577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sim/Desktop/TS Extrinsic Regression/TSER Code/compression.py:111: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array_flatdim_coeff[:,i] = np.array(coeff_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08  0.5298214703079772\n",
      "0.12  0.5484111092087927\n",
      "0.16  0.5703281943697189\n",
      "0.20  0.5945182596906888\n",
      "0.24  0.6220805539137043\n",
      "0.28  0.6525335907814673\n",
      "0.32  0.6872641619440751\n",
      "0.36  0.7262645281493676\n",
      "0.40  0.7698569443138238\n",
      "0.44  0.8219635057262874\n",
      "0.48  0.8801242421527342\n",
      "0.52  0.9504231384488364\n",
      "0.56  1.031451912105451\n",
      "0.60  1.1319853110643332\n",
      "0.64  1.2504434166419145\n",
      "0.68  1.4007738451739251\n",
      "0.72  1.5991708180032342\n",
      "0.76  1.8544584985211756\n",
      "0.80  2.203733062127965\n",
      "0.84  2.717858855646143\n",
      "0.88  3.5846247415156305\n",
      "0.92  5.167134240426427\n",
      "0.96  9.538192646297256\n",
      "1.00  326.70953436807093\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$$ dwt $$$\n",
      "RMSE\n",
      "0.00  6.572596242129255e-16\n",
      "0.04  6.572596242129255e-16\n",
      "0.08  6.572596242129255e-16\n",
      "0.12  6.572596242129255e-16\n",
      "0.16  6.572596242129255e-16\n",
      "0.20  6.572596242129255e-16\n",
      "0.24  6.572596242129255e-16\n",
      "0.28  6.572596242129255e-16\n",
      "0.32  8.911307321641015e-06\n",
      "0.36  0.0001301479619372805\n",
      "0.40  0.0005014920125440056\n",
      "0.44  0.0012832018310334002\n",
      "0.48  0.0028365160436743114\n",
      "0.52  0.005190893872088812\n",
      "0.56  0.009027974092687758\n",
      "0.60  0.014911185786874632\n",
      "0.64  0.023036347738617964\n",
      "0.68  0.034772589611323984\n",
      "0.72  0.0503533743367567\n",
      "0.76  0.07163064180633531\n",
      "0.80  0.09939737717180963\n",
      "0.84  0.1346613470678784\n",
      "0.88  0.18349667506251308\n",
      "0.92  0.2586318370775126\n",
      "0.96  0.4023598002694402\n",
      "1.00  1.0\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  0.7285592084769312\n",
      "0.04  0.7285592084769312\n",
      "0.08  0.7285592084769312\n",
      "0.12  0.7285592084769312\n",
      "0.16  0.7285592084769312\n",
      "0.20  0.7285592084769312\n",
      "0.24  0.7285592084769312\n",
      "0.28  0.7285592084769312\n",
      "0.32  0.728916020262783\n",
      "0.36  0.7300970681359846\n",
      "0.40  0.7358580082602116\n",
      "0.44  0.7476835642157609\n",
      "0.48  0.7642427385892117\n",
      "0.52  0.7868146890302186\n",
      "0.56  0.8213541144073938\n",
      "0.60  0.8722517552064217\n",
      "0.64  0.9400363647963252\n",
      "0.68  1.0323769486775267\n",
      "0.72  1.1581710854169451\n",
      "0.76  1.3299335692107734\n",
      "0.80  1.5724622214633313\n",
      "0.84  1.9237025915529735\n",
      "0.88  2.5091701718236465\n",
      "0.92  3.645734362628662\n",
      "0.96  6.901451990632318\n",
      "1.00  324.55066079295153\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:01, 56.87it/s] \n",
      "100%|██████████| 42/42 [00:00<00:00, 566.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ AppliancesEnergy +++\n",
      "$$$ dct $$$\n",
      "RMSE\n",
      "0.00  0.00640419263916621\n",
      "0.04  0.006409175324841004\n",
      "0.08  0.00663094586725514\n",
      "0.12  0.0074045921389583585\n",
      "0.16  0.008880953849950843\n",
      "0.20  0.01084628618474862\n",
      "0.24  0.01326502084415076\n",
      "0.28  0.01621357481896293\n",
      "0.32  0.019471185253031705\n",
      "0.36  0.02309876052735807\n",
      "0.40  0.027221807768175087\n",
      "0.44  0.03162035059920456\n",
      "0.48  0.036387637170388766\n",
      "0.52  0.041719065407272035\n",
      "0.56  0.04738455994277475\n",
      "0.60  0.0536230282038452\n",
      "0.64  0.06072920477657591\n",
      "0.68  0.06850644727212453\n",
      "0.72  0.07740721946698884\n",
      "0.76  0.08814803502339795\n",
      "0.80  0.10130865671866987\n",
      "0.84  0.11939142941826988\n",
      "0.88  0.14806464971819183\n",
      "0.92  0.1964391535014975\n",
      "0.96  0.29729375079702286\n",
      "1.00  0.9990079365079365\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  3.9482928515861353\n",
      "0.04  3.961602063000139\n",
      "0.08  3.9911168325828754\n",
      "0.12  4.031888288012617\n",
      "0.16  4.083235995232419\n",
      "0.20  4.151168708422698\n",
      "0.24  4.240839543462653\n",
      "0.28  4.339438733826072\n",
      "0.32  4.45706646891222\n",
      "0.36  4.58514240591038\n",
      "0.40  4.729627865559444\n",
      "0.44  4.895798499464094\n",
      "0.48  5.089221650288566\n",
      "0.52  5.32586339575123\n",
      "0.56  5.6039504355293825\n",
      "0.60  5.931308811690054\n",
      "0.64  6.348900564312123\n",
      "0.68  6.854686061867222\n",
      "0.72  7.488409456047739\n",
      "0.76  8.382683272976411\n",
      "0.80  9.590534979423868\n",
      "0.84  11.323389908939166\n",
      "0.88  14.099827139152982\n",
      "0.92  19.1414163989384\n",
      "0.96  32.39713461629391\n",
      "1.00  590.6612068965517\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$$ dft $$$\n",
      "RMSE\n",
      "0.00  4.716563769310973e-16\n",
      "0.04  0.004583315163733732\n",
      "0.08  0.008636672389426033\n",
      "0.12  0.01261045634831185\n",
      "0.16  0.01672391905651998\n",
      "0.20  0.020777521317342278\n",
      "0.24  0.02493819021983818\n",
      "0.28  0.029283085153301813\n",
      "0.32  0.03371476992329699\n",
      "0.36  0.03831300855543046\n",
      "0.40  0.04319567014836685\n",
      "0.44  0.048118693818055454\n",
      "0.48  0.053304094256427674\n",
      "0.52  0.05895233831774143\n",
      "0.56  0.06485000204346368\n",
      "0.60  0.07118150720683833\n",
      "0.64  0.07827151386715224\n",
      "0.68  0.08611328014478666\n",
      "0.72  0.09540474713736262\n",
      "0.76  0.10724159394519044\n",
      "0.80  0.12243007751530642\n",
      "0.84  0.14408143729081352\n",
      "0.88  0.1773871698027158\n",
      "0.92  0.2325578707293866\n",
      "0.96  0.3416909210225073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sim/Desktop/TS Extrinsic Regression/TSER Code/compression.py:111: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  array_flatdim_coeff[:,i] = np.array(coeff_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00  0.9990079365079365\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  0.8529032097443782\n",
      "0.04  0.8752772100153295\n",
      "0.08  0.9028862917285465\n",
      "0.12  0.9349999112990056\n",
      "0.16  0.9722390529152258\n",
      "0.20  1.01328634408141\n",
      "0.24  1.0594017153486128\n",
      "0.28  1.1131424393810163\n",
      "0.32  1.1722155119023585\n",
      "0.36  1.2395379549895071\n",
      "0.40  1.3179583357377807\n",
      "0.44  1.407321216204281\n",
      "0.48  1.511448916654534\n",
      "0.52  1.6379016064257028\n",
      "0.56  1.7845214220601642\n",
      "0.60  1.9615880123220686\n",
      "0.64  2.180747893783678\n",
      "0.68  2.4542123361272297\n",
      "0.72  2.8051528538032287\n",
      "0.76  3.2907181142297275\n",
      "0.80  3.937288817377313\n",
      "0.84  4.891010586278527\n",
      "0.88  6.470309932574083\n",
      "0.92  9.412927599945048\n",
      "0.96  17.41876191686793\n",
      "1.00  590.6612068965517\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "$$$ dwt $$$\n",
      "RMSE\n",
      "0.00  5.040426526181978e-16\n",
      "0.04  5.9936185917228813e-05\n",
      "0.08  0.00022562168391515022\n",
      "0.12  0.0005065031573571895\n",
      "0.16  0.0009068448209922664\n",
      "0.20  0.00143585406301341\n",
      "0.24  0.0021136602076584562\n",
      "0.28  0.0029188745445709826\n",
      "0.32  0.003894882641346664\n",
      "0.36  0.0050639930089214965\n",
      "0.40  0.006413852699226404\n",
      "0.44  0.00799068190153901\n",
      "0.48  0.009879410603003113\n",
      "0.52  0.012008669145238193\n",
      "0.56  0.014591228719718088\n",
      "0.60  0.017593535240536886\n",
      "0.64  0.02122324578210963\n",
      "0.68  0.025833203600940973\n",
      "0.72  0.03158233727992173\n",
      "0.76  0.03929192331272111\n",
      "0.80  0.050581594666246836\n",
      "0.84  0.06751192962142669\n",
      "0.88  0.09564984593214898\n",
      "0.92  0.15016313644217363\n",
      "0.96  0.2745041232561796\n",
      "1.00  0.9990079365079365\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  0.6557218120307587\n",
      "0.04  0.6673916897355825\n",
      "0.08  0.6853040608121624\n",
      "0.12  0.7080226801375192\n",
      "0.16  0.7338310029613841\n",
      "0.20  0.7639262706516431\n",
      "0.24  0.7982084878393161\n",
      "0.28  0.8359467076607737\n",
      "0.32  0.8784192307692308\n",
      "0.36  0.9277455590775717\n",
      "0.40  0.9828960392488775\n",
      "0.44  1.0460516974731413\n",
      "0.48  1.120953281547553\n",
      "0.52  1.206815347654241\n",
      "0.56  1.3108301750344846\n",
      "0.60  1.4336497055980315\n",
      "0.64  1.5828104786545925\n",
      "0.68  1.7746164784132321\n",
      "0.72  2.0144682952931734\n",
      "0.76  2.333349225755259\n",
      "0.80  2.7859338532475664\n",
      "0.84  3.4392135406732187\n",
      "0.88  4.495669461832211\n",
      "0.92  6.607203471552555\n",
      "0.96  12.481182599825123\n",
      "1.00  590.1524547803617\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5072it [00:11, 453.67it/s]\n",
      "100%|██████████| 5048/5048 [00:05<00:00, 956.84it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ BeijingPM25Quality +++\n",
      "$$$ dct $$$\n",
      "RMSE\n",
      "0.00  0.006296655226801784\n",
      "0.04  0.006767491197033571\n",
      "0.08  0.009779098648530462\n",
      "0.12  0.015174618387245507\n",
      "0.16  0.022436521356719908\n",
      "0.20  0.030842558023504028\n",
      "0.24  0.04036997033062279\n",
      "0.28  0.05118556973264827\n",
      "0.32  0.06273464099704099\n",
      "0.36  0.07526279945574325\n",
      "0.40  0.08908632733425607\n",
      "0.44  0.1035837257241737\n",
      "0.48  0.11916205385264451\n",
      "0.52  0.1363012633924039\n",
      "0.56  0.15422719821634923\n",
      "0.60  0.1734595226762815\n",
      "0.64  0.1947504823889541\n",
      "0.68  0.21730982158413797\n",
      "0.72  0.24200346925785005\n",
      "0.76  0.270243568445171\n",
      "0.80  0.3017254963179742\n",
      "0.84  0.3389340440091282\n",
      "0.88  0.38641056722499406\n",
      "0.92  0.44866441319583866\n",
      "0.96  0.5428084649958498\n",
      "1.00  0.8947437929212063\n",
      "\n",
      "\n",
      "Comp-Ratio\n",
      "0.00  3.610917276454746\n",
      "0.04  3.6256204589715284\n",
      "0.08  3.661167796305123\n",
      "0.12  3.711906039810898\n",
      "0.16  3.7759993690199685\n",
      "0.20  3.849015960322367\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_compression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/TSER Code/utils/personal_utils.py:122\u001b[0m, in \u001b[0;36mtest_compression\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.04\u001b[39m, \u001b[38;5;241m0.04\u001b[39m):\n\u001b[1;32m    121\u001b[0m     decompressed_dataset \u001b[38;5;241m=\u001b[39m compress_dataset(dataset_array\u001b[38;5;241m.\u001b[39mcopy(), dataset_id, \u001b[38;5;28;01mFalse\u001b[39;00m, comp_tq, i) \n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mcalculateCompRatio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_array\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mdecompressed_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/TSER Code/compression.py:150\u001b[0m, in \u001b[0;36mcalculateCompRatio\u001b[0;34m(dataset_array, array_flatdim_comp)\u001b[0m\n\u001b[1;32m    146\u001b[0m compressed_data_bytestring \u001b[38;5;241m=\u001b[39m array_flatdim_1d\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# Compress the byte-string with gzip. -> Input is byte string and then returns a byte-string. ->> Test more by yourself!\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m compressed_data_gzipd \u001b[38;5;241m=\u001b[39m \u001b[43mgzip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompressed_data_bytestring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompresslevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;66;03m# .nbytes simply returns: np.prod(a.shape) * a.itemsize -> simply how many bytes are filled in the array. No metadata. Only counts the byte of the elements.\u001b[39;00m\n\u001b[1;32m    154\u001b[0m num_bytes_raw \u001b[38;5;241m=\u001b[39m dataset_array\u001b[38;5;241m.\u001b[39mnbytes\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:549\u001b[0m, in \u001b[0;36mcompress\u001b[0;34m(data, compresslevel, mtime)\u001b[0m\n\u001b[1;32m    547\u001b[0m buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m GzipFile(fileobj\u001b[38;5;241m=\u001b[39mbuf, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, compresslevel\u001b[38;5;241m=\u001b[39mcompresslevel, mtime\u001b[38;5;241m=\u001b[39mmtime) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 549\u001b[0m     \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "File \u001b[0;32m/usr/lib/python3.10/gzip.py:289\u001b[0m, in \u001b[0;36mGzipFile.write\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    286\u001b[0m     length \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mnbytes\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc \u001b[38;5;241m=\u001b[39m zlib\u001b[38;5;241m.\u001b[39mcrc32(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrc)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_compression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:01, 62.48it/s] \n",
      "100%|██████████| 42/42 [00:00<00:00, 642.88it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/sim/Desktop/TS Extrinsic Regression/data/AppliancesEnergy_TEST.ts\"\n",
    "dataset_array = load_dataset(data_path)\n",
    "dataset_id = os.path.basename(data_path).split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0   5.040426526181978e-16\n",
      "0.1   0.0003464869636634713\n",
      "0.2   0.00143585406301341\n",
      "0.30000000000000004   0.0033854854425775997\n",
      "0.4   0.006413852699226404\n",
      "0.5   0.010901034462780138\n",
      "0.6000000000000001   0.017593535240536886\n",
      "0.7000000000000001   0.02851264206464209\n",
      "0.8   0.050581594666246836\n",
      "0.9   0.11883603009165886\n",
      "1.0   0.9990079365079365\n"
     ]
    }
   ],
   "source": [
    "# Check if RMSE increases with increasing dropout_ratio\n",
    "for i in np.arange(0, 1.04, 0.1):\n",
    "    decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, True, \"dwt\", i) \n",
    "    print(i, \" \" ,compute_avg_rmse_of_dataset(dataset_array, decompressed_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6557218120307587\n",
      "0.695904811237393\n",
      "0.7639262706516431\n",
      "0.8564384095877723\n",
      "0.9828960392488775\n",
      "1.16226921432788\n",
      "1.4336497055980315\n",
      "1.8868002985099288\n",
      "2.7859338532475664\n",
      "5.364644258097855\n"
     ]
    }
   ],
   "source": [
    "# Check that Compression Ratio increases with increasing dropout_ratio\n",
    "for i in np.arange(0, 1, 0.1):\n",
    "    decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, False, \"dwt\", i) \n",
    "    print(calculateCompRatio(dataset_array, decompressed_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23]\n",
      "  [24 25 26 27]\n",
      "  [28 29 30 31]\n",
      "  [32 33 34 35]\n",
      "  [36 37 38 39]]]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]\n",
      " [24 25 26 27]\n",
      " [28 29 30 31]\n",
      " [32 33 34 35]\n",
      " [36 37 38 39]]\n",
      "[ 0  4  8 12 16 20 24 28 32 36  1  5  9 13 17 21 25 29 33 37  2  6 10 14\n",
      " 18 22 26 30 34 38  3  7 11 15 19 23 27 31 35 39]\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23]\n",
      "  [24 25 26 27]\n",
      "  [28 29 30 31]\n",
      "  [32 33 34 35]\n",
      "  [36 37 38 39]]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "# Test if reshaping from (len_flat_dim, dim) to (num_dp, len_ts, dim) is working\n",
    "num_dp = 2\n",
    "len_ts = 5\n",
    "num_dim = 4\n",
    "\n",
    "array = np.arange(num_dp * len_ts * num_dim).reshape(num_dp, len_ts, num_dim)\n",
    "print(array)\n",
    "\n",
    "# Reshape to (len_flat_dim, dim)\n",
    "array_flatdim = array.reshape(num_dp * len_ts, num_dim)\n",
    "print(array_flatdim)\n",
    "\n",
    "# Put column after column. For gzip part.\n",
    "print(array_flatdim.reshape(-1, order='F'))\n",
    "\n",
    "\n",
    "# Reshape back to (num_dp, len_ts, dim)\n",
    "array_back = array_flatdim.reshape(-1, len_ts, num_dim)\n",
    "print(array_back)\n",
    "\n",
    "print(array_back.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "int64\n",
      "<class 'bytearray'>\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Test binary conversion and compression\n",
    "num_dp = 2\n",
    "len_ts = 2\n",
    "num_dim = 2\n",
    "\n",
    "array = np.arange(num_dp * len_ts * num_dim).reshape(num_dp, len_ts, num_dim)\n",
    "array_flat = array.reshape(num_dp * len_ts, num_dim)\n",
    "\n",
    "# Test if .tobytes saves metadata of the np.array -> No it flattens the array row after row (and slice after slice), then just saves the content of the array as bytes!\n",
    "print(array_flat.tobytes() == np.arange(8).tobytes())\n",
    "\n",
    "\n",
    "byte_nparray = np.arange(5)\n",
    "print(byte_nparray.dtype)\n",
    "\n",
    "byte_nparray = byte_nparray.tobytes()\n",
    "\n",
    "print(bytearray)\n",
    "print(len(byte_nparray))\n",
    "\n",
    "# len(byte-string) -> return number of bytes in byte-object!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if saving with tofile keeps the array the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test Saving in Files\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_series.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtrain_x_p\u001b[49m)\n\u001b[1;32m      4\u001b[0m train_x_p[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m      7\u001b[0m flattened \u001b[38;5;241m=\u001b[39m train_x_p\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_p' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Saving in Files\n",
    "\n",
    "np.save('time_series.npy', train_x_p)\n",
    "train_x_p[0][0][0].dtype\n",
    "\n",
    "\n",
    "flattened = train_x_p.flatten()\n",
    "flattened.tofile(\"data.bin\")\n",
    "\n",
    "train_after = np.fromfile(\"data.bin\", dtype=train_x_p[0][0][0].dtype)\n",
    "train_after.shape\n",
    "if np.array_equal(flattened, train_after):\n",
    "    print(\"The arrays have the same content.\")\n",
    "else:\n",
    "    print(\"The arrays do not have the same content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only preparing Data for Testing!\n",
    "\n",
    "def prepare_data(data_x_p, data_y):\n",
    "\n",
    "    # Swap the dimensions so that columns are stacked after each other. Copy since swapaxes only returns a view\n",
    "    #(95, 144, 24) -> (95, 24, 144), first column gets first row etc. One Row is the ts of the belonging dimension.\n",
    "    data_swapped = data_x_p.swapaxes(1, 2).copy()\n",
    "\n",
    "    # Reshape to flattened ts. Stack the rows behind the other for each slice.\n",
    "    data_x_flattend = data_swapped.reshape(data_swapped.shape[0], -1)\n",
    "    \n",
    "\n",
    "    prep_data = pd.DataFrame(data_x_flattend)\n",
    "    prep_data['target'] = data_y\n",
    "    prep_data.columns = prep_data.columns.astype(str) #fwiz or flaml needs string as columns!\n",
    "\n",
    "   \n",
    "    #data_x_p = data_x_p[0:2,...]\n",
    "\n",
    "    num_datapoints = data_x_p.shape[0]\n",
    "    len_timeseries = data_x_p.shape[1]\n",
    "    num_dimensions = data_x_p.shape[2]\n",
    "    num_features = 38\n",
    "\n",
    "    all_features = np.ndarray((num_datapoints, num_features * num_dimensions))\n",
    "\n",
    "    for i in range(0, num_datapoints):\n",
    "        start_index = 0\n",
    "\n",
    "        for j in range(0, num_dimensions):\n",
    "            curr_ts = data_x_p[i,:,j]\n",
    "\n",
    "            #print(curr_ts.size)\n",
    "\n",
    "            timeseries_df = pd.DataFrame({'unique_id' : np.ones(len_timeseries),'ds': np.arange(0, len_timeseries) , 'y': curr_ts})\n",
    "            \n",
    "            feature_array = tsfeatures(timeseries_df, freq=1).fillna(0).values\n",
    "\n",
    "            #print(feature_array.size)\n",
    "            #print(np.isnan(feature_array).sum())\n",
    "\n",
    "            end_index = start_index + feature_array.size\n",
    "            all_features[i, start_index: end_index] = feature_array\n",
    "            start_index = end_index\n",
    "        \n",
    "\n",
    "    all_features = pd.DataFrame(all_features)\n",
    "\n",
    "    # name the features\n",
    "    for i, col in enumerate(all_features.columns):\n",
    "        # Generate the new column name\n",
    "        new_col_name = 'f' + str(i + 1)\n",
    "        # Rename the column\n",
    "        all_features.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ts_and_features = pd.concat([prep_data, all_features], axis=1)\n",
    "\n",
    "\n",
    "    all_features['target'] = data_y\n",
    "\n",
    "    ts_and_features = pd.concat([prep_data.drop(columns=['target']), all_features], axis=1)\n",
    "    \n",
    "    #prep_data.columns = prep_data.columns.astype(str)\n",
    "\n",
    "    return ts_and_features, all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test preparing part function of load_and_prepare_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00000000e+00  3.74540119e-01]\n",
      "  [ 1.00000000e+00  9.50714306e-01]\n",
      "  [ 2.00000000e+00  7.31993942e-01]]\n",
      "\n",
      " [[ 0.00000000e+00  7.49080238e-02]\n",
      "  [ 1.22464680e-16  1.19014286e+00]\n",
      "  [-2.44929360e-16  2.14639879e+00]]]\n",
      "[[ 1.00000000e+00  5.00000000e-01  3.00000000e+00  4.44089210e-16\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.35200499e+02  0.00000000e+00  9.99999985e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  6.66801831e-01  3.00000000e+00 -2.75921612e+00\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.15119426e+02  0.00000000e+00  1.49011612e-08  1.47344817e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  2.00000000e+00  0.00000000e+00\n",
      "  -4.14940655e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  7.15004181e-01  3.00000000e+00 -8.00000000e+00\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.41667483e+02  0.00000000e+00  1.49011613e-08  1.47776810e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.26435418e-31  2.00000000e+00  0.00000000e+00\n",
      "  -3.80952381e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  5.59880864e-01  3.00000000e+00 -2.85103917e-01\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   6.95053958e+02  0.00000000e+00  1.49011612e-08  1.22257941e-11\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  8.75840729e-31  1.00000000e+00  0.00000000e+00\n",
      "  -1.30631734e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "     0             1             2         3         4         5   f1  \\\n",
      "0  0.0  1.000000e+00  2.000000e+00  0.374540  0.950714  0.731994  1.0   \n",
      "1  0.0  1.224647e-16 -2.449294e-16  0.074908  1.190143  2.146399  1.0   \n",
      "\n",
      "         f2   f3            f4  ...           f68  f69  f70       f71  f72  \\\n",
      "0  0.500000  3.0  4.440892e-16  ... -0.000000e+00  2.0  0.0 -0.414941  0.0   \n",
      "1  0.715004  3.0 -8.000000e+00  ...  8.758407e-31  1.0  0.0 -0.001306  0.0   \n",
      "\n",
      "   f73  f74  f75  f76  target  \n",
      "0  0.0  0.0  0.0  0.0       0  \n",
      "1  0.0  0.0  0.0  0.0       1  \n",
      "\n",
      "[2 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "# Simple test:\n",
    "#-> No a perfect test, but it seems to work! I have no idea about better tests!\n",
    "\n",
    "len_ts = 3\n",
    "ts_1_v = np.arange(len_ts)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "ts_2_v = np.random.rand(len_ts)\n",
    "x = np.linspace(0, 2 * np.pi, len_ts)\n",
    "ts_3_v = np.sin(x)\n",
    "\n",
    "ts_4_v =  ts_1_v + 0.2 * ts_2_v\n",
    "\n",
    "\n",
    "# Reulting Feature matrix\n",
    "ts_1 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_1_v})\n",
    "ts_2 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_2_v})\n",
    "ts_3 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_3_v})\n",
    "ts_4 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_4_v})\n",
    "\n",
    "feature_matrix = np.vstack((tsfeatures(ts_1, freq=1).fillna(0).values, tsfeatures(ts_2, freq=1).fillna(0).values, tsfeatures(ts_3, freq=1).fillna(0).values,tsfeatures(ts_4, freq=1).fillna(0).values))\n",
    "#print(feature_matrix)\n",
    "\n",
    "\n",
    "layer1 = np.stack((ts_1_v, ts_2_v), axis=1)\n",
    "layer2 = np.stack((ts_3_v,ts_4_v), axis=1)\n",
    "\n",
    "input = np.stack((layer1, layer2), axis=0)\n",
    "\n",
    "\n",
    "print(input)\n",
    "print(feature_matrix)\n",
    "tsf, f = prepare_data(input, np.arange(2))\n",
    "print(tsf)\n",
    "#print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1    2    3    4    5    6    7    8    9  ...      f144  f145  \\\n",
       " 0    0    4    8   12   16   20   24   28   32   36  ...  0.521199   1.0   \n",
       " 1  120  124  128  132  136  140  144  148  152  156  ...  0.521199   1.0   \n",
       " 2  240  244  248  252  256  260  264  268  272  276  ...  0.521199   1.0   \n",
       " \n",
       "    f146  f147      f148      f149      f150      f151     f152    target  \n",
       " 0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.388170  \n",
       " 1   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.643288  \n",
       " 2   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.458253  \n",
       " \n",
       " [3 rows x 273 columns],\n",
       "     f1        f2    f3   f4        f5   f6   f7   f8        f9  f10  ...  \\\n",
       " 0  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " 1  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " 2  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " \n",
       "        f144  f145  f146  f147      f148      f149      f150      f151  \\\n",
       " 0  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " 1  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " 2  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " \n",
       "       f152    target  \n",
       " 0  0.53624  0.388170  \n",
       " 1  0.53624  0.643288  \n",
       " 2  0.53624  0.458253  \n",
       " \n",
       " [3 rows x 153 columns])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Sample TS\n",
    "linear_data = linear_data = np.arange(360).reshape(3, 30, 4)  # Creates an array with values from 0 to 1199\n",
    "linear_data\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "random_data = np.random.rand(3, 30, 4)\n",
    "random_y = np.random.rand(3)\n",
    "random_data\n",
    "\n",
    "prepare_data(linear_data, random_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvAutogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
