{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.data_loader import load_from_tsfile_to_dataframe\n",
    "from utils.regressor_tools import process_data\n",
    "#import mlflow\n",
    "#from tsfeatures import tsfeatures\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "#pd.set_option('display.max_rows', None)  \n",
    "#pd.set_option('display.max_columns', None) \n",
    "from utils.personal_utils import *\n",
    "from compression import *\n",
    "from utils.compression_algos import *\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to see if the compression code still works properly\n",
    "What we should get:\n",
    "- Imcreasing RSME and Compression Ratio\n",
    "- RSME of dropout 0 should be nearly zero. RSME for dropout 1 should be around 1.\n",
    "- Compression Ratio should make sense! Super high for dropout_value close to 1. For droput_value around 0.8, 0.9 Ratio of 3 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' def test_compression():\\n\\n    paths = {\\n    \\'AppliancesEnergy\\':   \\'/home/sim/Desktop/TS Extrinsic Regression/data/AppliancesEnergy_TEST.ts\\',\\n    \\'BeijingPM25Quality\\': \\'/home/sim/Desktop/TS Extrinsic Regression/data/BeijingPM25Quality_TEST.ts\\',\\n    \\'NewsTitleSentiment\\': \\'/home/sim/Desktop/TS Extrinsic Regression/data/Covid3Month_TEST.ts\\'\\n    }\\n    comp_techniques = [\\'dct\\',\\'dft\\',\\'dwt\\']\\n    \\n\\n\\n\\n    for path in paths:\\n        data_path = paths[path]\\n\\n        dataset_array = load_dataset(data_path)\\n        dataset_id = os.path.basename(data_path).split(\\'_\\')[0]\\n\\n        print(f\"+++ {dataset_id} +++\")\\n\\n        for comp_tq in comp_techniques:\\n            print(f\"$$$ {comp_tq} $$$\")\\n\\n            print(\"RMSE\")\\n            for i in np.arange(0, 1.04, 0.04):\\n                decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, True, \"dwt\", i) \\n                print(f\"{i:.2f}  {compute_avg_rmse_of_dataset(dataset_array, decompressed_dataset)}\")\\n\\n            print(\"\\n\")\\n\\n            print(\"Comp-Ratio\")\\n            for i in np.arange(0, 1.04, 0.04):\\n                decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, False, \"dwt\", i) \\n                print(f\"{i:.2f}  {calculateCompRatio(dataset_array, decompressed_dataset)}\")\\n\\n            print(\"\\n\")\\n            print(\"\\n\") '"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" def test_compression():\n",
    "\n",
    "    paths = {\n",
    "    'AppliancesEnergy':   '/home/sim/Desktop/TS Extrinsic Regression/data/AppliancesEnergy_TEST.ts',\n",
    "    'BeijingPM25Quality': '/home/sim/Desktop/TS Extrinsic Regression/data/BeijingPM25Quality_TEST.ts',\n",
    "    'NewsTitleSentiment': '/home/sim/Desktop/TS Extrinsic Regression/data/Covid3Month_TEST.ts'\n",
    "    }\n",
    "    comp_techniques = ['dct','dft','dwt']\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    for path in paths:\n",
    "        data_path = paths[path]\n",
    "\n",
    "        dataset_array = load_dataset(data_path)\n",
    "        dataset_id = os.path.basename(data_path).split('_')[0]\n",
    "\n",
    "        print(f\"+++ {dataset_id} +++\")\n",
    "\n",
    "        for comp_tq in comp_techniques:\n",
    "            print(f\"$$$ {comp_tq} $$$\")\n",
    "\n",
    "            print(\"RMSE\")\n",
    "            for i in np.arange(0, 1.04, 0.04):\n",
    "                decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, True, \"dwt\", i) \n",
    "                print(f\"{i:.2f}  {compute_avg_rmse_of_dataset(dataset_array, decompressed_dataset)}\")\n",
    "\n",
    "            print(\"\\n\")\n",
    "\n",
    "            print(\"Comp-Ratio\")\n",
    "            for i in np.arange(0, 1.04, 0.04):\n",
    "                decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, False, \"dwt\", i) \n",
    "                print(f\"{i:.2f}  {calculateCompRatio(dataset_array, decompressed_dataset)}\")\n",
    "\n",
    "            print(\"\\n\")\n",
    "            print(\"\\n\") \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "66it [00:01, 62.53it/s] \n",
      "100%|██████████| 42/42 [00:00<00:00, 638.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ AppliancesEnergy +++\n",
      "$$$ dct $$$\n",
      "RMSE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'compress_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_compression\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/TSER Code/utils/personal_utils.py:112\u001b[0m, in \u001b[0;36mtest_compression\u001b[0;34m()\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRMSE\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.04\u001b[39m, \u001b[38;5;241m0.04\u001b[39m):\n\u001b[0;32m--> 112\u001b[0m     decompressed_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcompress_dataset\u001b[49m(dataset_array\u001b[38;5;241m.\u001b[39mcopy(), dataset_id, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdwt\u001b[39m\u001b[38;5;124m\"\u001b[39m, i) \n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompute_avg_rmse_of_dataset(dataset_array,\u001b[38;5;250m \u001b[39mdecompressed_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'compress_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "test_compression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/home/sim/Desktop/TS Extrinsic Regression/data/AppliancesEnergy_TEST.ts\"\n",
    "dataset_array = load_dataset(data_path)\n",
    "dataset_id = os.path.basename(data_path).split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0   5.040426526181978e-16\n",
      "0.1   0.0003464869636634713\n",
      "0.2   0.00143585406301341\n",
      "0.30000000000000004   0.0033854854425775997\n",
      "0.4   0.006413852699226404\n",
      "0.5   0.010901034462780138\n",
      "0.6000000000000001   0.017593535240536886\n",
      "0.7000000000000001   0.02851264206464209\n",
      "0.8   0.050581594666246836\n",
      "0.9   0.11883603009165886\n",
      "1.0   0.9990079365079365\n"
     ]
    }
   ],
   "source": [
    "# Check if RMSE increases with increasing dropout_ratio\n",
    "for i in np.arange(0, 1.04, 0.1):\n",
    "    decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, True, \"dwt\", i) \n",
    "    print(i, \" \" ,compute_avg_rmse_of_dataset(dataset_array, decompressed_dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6557218120307587\n",
      "0.6573007353258602\n",
      "0.6600157787203054\n",
      "0.6634245860416568\n",
      "0.6673916897355825\n",
      "0.671529577343312\n",
      "0.6758870705217366\n",
      "0.6804372804634983\n",
      "0.6853040608121624\n",
      "0.6904788538224561\n",
      "0.695904811237393\n",
      "0.7015574875823873\n",
      "0.7080226801375192\n",
      "0.714039174000719\n",
      "0.7203420212391278\n",
      "0.7270123784805855\n",
      "0.7338310029613841\n",
      "0.7410335168341247\n",
      "0.7484769203039059\n",
      "0.756073042027415\n",
      "0.7639262706516431\n",
      "0.7719591378247775\n",
      "0.7802204809769395\n",
      "0.7896931550867471\n",
      "0.7982084878393161\n",
      "0.8073611029281801\n",
      "0.8166228658264056\n",
      "0.8261852567302614\n",
      "0.8359467076607737\n",
      "0.8461118595969538\n",
      "0.8564384095877723\n",
      "0.8672286457443374\n",
      "0.8784192307692308\n",
      "0.8898099387674266\n",
      "0.9029279362385152\n",
      "0.9151202455397092\n",
      "0.9277455590775717\n",
      "0.9408623338958823\n",
      "0.9545494440582286\n",
      "0.9684120217775993\n",
      "0.9828960392488775\n",
      "0.9977327135792545\n",
      "1.0131679733594376\n",
      "1.0293202133253212\n",
      "1.0460516974731413\n",
      "1.0650451873245435\n",
      "1.0828947493196022\n",
      "1.1014962228692047\n",
      "1.120953281547553\n",
      "1.1410815816032536\n",
      "1.16226921432788\n",
      "1.1839577404187598\n",
      "1.206815347654241\n",
      "1.2304734641687258\n",
      "1.2551880674448768\n",
      "1.2811912735677062\n",
      "1.3108301750344846\n",
      "1.3393573433627073\n",
      "1.3693562796163539\n",
      "1.400655387835871\n",
      "1.4336497055980315\n",
      "1.4682170974529964\n",
      "1.5044529736993497\n",
      "1.5427276432191692\n",
      "1.5828104786545925\n",
      "1.6253593896780438\n",
      "1.6706582008104984\n",
      "1.7234044158705724\n",
      "1.7746164784132321\n",
      "1.8288042535359386\n",
      "1.8868002985099288\n",
      "1.9480855129039871\n",
      "2.0144682952931734\n",
      "2.0852618572263344\n",
      "2.1615532890191465\n",
      "2.2442490804096966\n",
      "2.333349225755259\n",
      "2.429454835564223\n",
      "2.544894366197183\n",
      "2.65972718238564\n",
      "2.7859338532475664\n",
      "2.9238657312576812\n",
      "3.0775902726933806\n",
      "3.2481760129705743\n",
      "3.4392135406732187\n",
      "3.6536199348374403\n",
      "3.8965809438232917\n",
      "4.173140055425282\n",
      "4.495669461832211\n",
      "4.91078173491109\n",
      "5.364644258097855\n",
      "5.921569135834479\n",
      "6.607203471552555\n",
      "7.469958461890693\n",
      "8.618778067096871\n",
      "10.191387773315483\n",
      "12.481182599825123\n",
      "16.160361337798953\n",
      "23.006850005036767\n",
      "40.32054375331019\n"
     ]
    }
   ],
   "source": [
    "# Check that Compression Ratio increases with increasing dropout_ratio\n",
    "for i in np.arange(0, 1, 0.1):\n",
    "    decompressed_dataset = compress_dataset(dataset_array.copy(), dataset_id, False, \"dwt\", i) \n",
    "    print(calculateCompRatio(dataset_array, decompressed_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23]\n",
      "  [24 25 26 27]\n",
      "  [28 29 30 31]\n",
      "  [32 33 34 35]\n",
      "  [36 37 38 39]]]\n",
      "[[ 0  1  2  3]\n",
      " [ 4  5  6  7]\n",
      " [ 8  9 10 11]\n",
      " [12 13 14 15]\n",
      " [16 17 18 19]\n",
      " [20 21 22 23]\n",
      " [24 25 26 27]\n",
      " [28 29 30 31]\n",
      " [32 33 34 35]\n",
      " [36 37 38 39]]\n",
      "[ 0  4  8 12 16 20 24 28 32 36  1  5  9 13 17 21 25 29 33 37  2  6 10 14\n",
      " 18 22 26 30 34 38  3  7 11 15 19 23 27 31 35 39]\n",
      "[[[ 0  1  2  3]\n",
      "  [ 4  5  6  7]\n",
      "  [ 8  9 10 11]\n",
      "  [12 13 14 15]\n",
      "  [16 17 18 19]]\n",
      "\n",
      " [[20 21 22 23]\n",
      "  [24 25 26 27]\n",
      "  [28 29 30 31]\n",
      "  [32 33 34 35]\n",
      "  [36 37 38 39]]]\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39]\n"
     ]
    }
   ],
   "source": [
    "# Test if reshaping from (len_flat_dim, dim) to (num_dp, len_ts, dim) is working\n",
    "num_dp = 2\n",
    "len_ts = 5\n",
    "num_dim = 4\n",
    "\n",
    "array = np.arange(num_dp * len_ts * num_dim).reshape(num_dp, len_ts, num_dim)\n",
    "print(array)\n",
    "\n",
    "# Reshape to (len_flat_dim, dim)\n",
    "array_flatdim = array.reshape(num_dp * len_ts, num_dim)\n",
    "print(array_flatdim)\n",
    "\n",
    "# Put column after column. For gzip part.\n",
    "print(array_flatdim.reshape(-1, order='F'))\n",
    "\n",
    "\n",
    "# Reshape back to (num_dp, len_ts, dim)\n",
    "array_back = array_flatdim.reshape(-1, len_ts, num_dim)\n",
    "print(array_back)\n",
    "\n",
    "print(array_back.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "int64\n",
      "<class 'bytearray'>\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Test binary conversion and compression\n",
    "num_dp = 2\n",
    "len_ts = 2\n",
    "num_dim = 2\n",
    "\n",
    "array = np.arange(num_dp * len_ts * num_dim).reshape(num_dp, len_ts, num_dim)\n",
    "array_flat = array.reshape(num_dp * len_ts, num_dim)\n",
    "\n",
    "# Test if .tobytes saves metadata of the np.array -> No it flattens the array row after row (and slice after slice), then just saves the content of the array as bytes!\n",
    "print(array_flat.tobytes() == np.arange(8).tobytes())\n",
    "\n",
    "\n",
    "byte_nparray = np.arange(5)\n",
    "print(byte_nparray.dtype)\n",
    "\n",
    "byte_nparray = byte_nparray.tobytes()\n",
    "\n",
    "print(bytearray)\n",
    "print(len(byte_nparray))\n",
    "\n",
    "# len(byte-string) -> return number of bytes in byte-object!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if saving with tofile keeps the array the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_x_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test Saving in Files\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m np\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime_series.npy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mtrain_x_p\u001b[49m)\n\u001b[1;32m      4\u001b[0m train_x_p[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m      7\u001b[0m flattened \u001b[38;5;241m=\u001b[39m train_x_p\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_x_p' is not defined"
     ]
    }
   ],
   "source": [
    "# Test Saving in Files\n",
    "\n",
    "np.save('time_series.npy', train_x_p)\n",
    "train_x_p[0][0][0].dtype\n",
    "\n",
    "\n",
    "flattened = train_x_p.flatten()\n",
    "flattened.tofile(\"data.bin\")\n",
    "\n",
    "train_after = np.fromfile(\"data.bin\", dtype=train_x_p[0][0][0].dtype)\n",
    "train_after.shape\n",
    "if np.array_equal(flattened, train_after):\n",
    "    print(\"The arrays have the same content.\")\n",
    "else:\n",
    "    print(\"The arrays do not have the same content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only preparing Data for Testing!\n",
    "\n",
    "def prepare_data(data_x_p, data_y):\n",
    "\n",
    "    # Swap the dimensions so that columns are stacked after each other. Copy since swapaxes only returns a view\n",
    "    #(95, 144, 24) -> (95, 24, 144), first column gets first row etc. One Row is the ts of the belonging dimension.\n",
    "    data_swapped = data_x_p.swapaxes(1, 2).copy()\n",
    "\n",
    "    # Reshape to flattened ts. Stack the rows behind the other for each slice.\n",
    "    data_x_flattend = data_swapped.reshape(data_swapped.shape[0], -1)\n",
    "    \n",
    "\n",
    "    prep_data = pd.DataFrame(data_x_flattend)\n",
    "    prep_data['target'] = data_y\n",
    "    prep_data.columns = prep_data.columns.astype(str) #fwiz or flaml needs string as columns!\n",
    "\n",
    "   \n",
    "    #data_x_p = data_x_p[0:2,...]\n",
    "\n",
    "    num_datapoints = data_x_p.shape[0]\n",
    "    len_timeseries = data_x_p.shape[1]\n",
    "    num_dimensions = data_x_p.shape[2]\n",
    "    num_features = 38\n",
    "\n",
    "    all_features = np.ndarray((num_datapoints, num_features * num_dimensions))\n",
    "\n",
    "    for i in range(0, num_datapoints):\n",
    "        start_index = 0\n",
    "\n",
    "        for j in range(0, num_dimensions):\n",
    "            curr_ts = data_x_p[i,:,j]\n",
    "\n",
    "            #print(curr_ts.size)\n",
    "\n",
    "            timeseries_df = pd.DataFrame({'unique_id' : np.ones(len_timeseries),'ds': np.arange(0, len_timeseries) , 'y': curr_ts})\n",
    "            \n",
    "            feature_array = tsfeatures(timeseries_df, freq=1).fillna(0).values\n",
    "\n",
    "            #print(feature_array.size)\n",
    "            #print(np.isnan(feature_array).sum())\n",
    "\n",
    "            end_index = start_index + feature_array.size\n",
    "            all_features[i, start_index: end_index] = feature_array\n",
    "            start_index = end_index\n",
    "        \n",
    "\n",
    "    all_features = pd.DataFrame(all_features)\n",
    "\n",
    "    # name the features\n",
    "    for i, col in enumerate(all_features.columns):\n",
    "        # Generate the new column name\n",
    "        new_col_name = 'f' + str(i + 1)\n",
    "        # Rename the column\n",
    "        all_features.rename(columns={col: new_col_name}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    ts_and_features = pd.concat([prep_data, all_features], axis=1)\n",
    "\n",
    "\n",
    "    all_features['target'] = data_y\n",
    "\n",
    "    ts_and_features = pd.concat([prep_data.drop(columns=['target']), all_features], axis=1)\n",
    "    \n",
    "    #prep_data.columns = prep_data.columns.astype(str)\n",
    "\n",
    "    return ts_and_features, all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test preparing part function of load_and_prepare_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.00000000e+00  3.74540119e-01]\n",
      "  [ 1.00000000e+00  9.50714306e-01]\n",
      "  [ 2.00000000e+00  7.31993942e-01]]\n",
      "\n",
      " [[ 0.00000000e+00  7.49080238e-02]\n",
      "  [ 1.22464680e-16  1.19014286e+00]\n",
      "  [-2.44929360e-16  2.14639879e+00]]]\n",
      "[[ 1.00000000e+00  5.00000000e-01  3.00000000e+00  4.44089210e-16\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.35200499e+02  0.00000000e+00  9.99999985e-01  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  6.66801831e-01  3.00000000e+00 -2.75921612e+00\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.15119426e+02  0.00000000e+00  1.49011612e-08  1.47344817e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00 -0.00000000e+00  2.00000000e+00  0.00000000e+00\n",
      "  -4.14940655e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  7.15004181e-01  3.00000000e+00 -8.00000000e+00\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   7.41667483e+02  0.00000000e+00  1.49011613e-08  1.47776810e-08\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  1.26435418e-31  2.00000000e+00  0.00000000e+00\n",
      "  -3.80952381e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.00000000e+00  5.59880864e-01  3.00000000e+00 -2.85103917e-01\n",
      "   3.33333333e-01  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   6.95053958e+02  0.00000000e+00  1.49011612e-08  1.22257941e-11\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   1.00000000e+00  8.75840729e-31  1.00000000e+00  0.00000000e+00\n",
      "  -1.30631734e-03  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "     0             1             2         3         4         5   f1  \\\n",
      "0  0.0  1.000000e+00  2.000000e+00  0.374540  0.950714  0.731994  1.0   \n",
      "1  0.0  1.224647e-16 -2.449294e-16  0.074908  1.190143  2.146399  1.0   \n",
      "\n",
      "         f2   f3            f4  ...           f68  f69  f70       f71  f72  \\\n",
      "0  0.500000  3.0  4.440892e-16  ... -0.000000e+00  2.0  0.0 -0.414941  0.0   \n",
      "1  0.715004  3.0 -8.000000e+00  ...  8.758407e-31  1.0  0.0 -0.001306  0.0   \n",
      "\n",
      "   f73  f74  f75  f76  target  \n",
      "0  0.0  0.0  0.0  0.0       0  \n",
      "1  0.0  0.0  0.0  0.0       1  \n",
      "\n",
      "[2 rows x 83 columns]\n"
     ]
    }
   ],
   "source": [
    "# Simple test:\n",
    "#-> No a perfect test, but it seems to work! I have no idea about better tests!\n",
    "\n",
    "len_ts = 3\n",
    "ts_1_v = np.arange(len_ts)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "ts_2_v = np.random.rand(len_ts)\n",
    "x = np.linspace(0, 2 * np.pi, len_ts)\n",
    "ts_3_v = np.sin(x)\n",
    "\n",
    "ts_4_v =  ts_1_v + 0.2 * ts_2_v\n",
    "\n",
    "\n",
    "# Reulting Feature matrix\n",
    "ts_1 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_1_v})\n",
    "ts_2 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_2_v})\n",
    "ts_3 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_3_v})\n",
    "ts_4 = pd.DataFrame({'unique_id' : np.ones(len_ts),'ds': np.arange(0,len_ts) , 'y': ts_4_v})\n",
    "\n",
    "feature_matrix = np.vstack((tsfeatures(ts_1, freq=1).fillna(0).values, tsfeatures(ts_2, freq=1).fillna(0).values, tsfeatures(ts_3, freq=1).fillna(0).values,tsfeatures(ts_4, freq=1).fillna(0).values))\n",
    "#print(feature_matrix)\n",
    "\n",
    "\n",
    "layer1 = np.stack((ts_1_v, ts_2_v), axis=1)\n",
    "layer2 = np.stack((ts_3_v,ts_4_v), axis=1)\n",
    "\n",
    "input = np.stack((layer1, layer2), axis=0)\n",
    "\n",
    "\n",
    "print(input)\n",
    "print(feature_matrix)\n",
    "tsf, f = prepare_data(input, np.arange(2))\n",
    "print(tsf)\n",
    "#print(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     0    1    2    3    4    5    6    7    8    9  ...      f144  f145  \\\n",
       " 0    0    4    8   12   16   20   24   28   32   36  ...  0.521199   1.0   \n",
       " 1  120  124  128  132  136  140  144  148  152  156  ...  0.521199   1.0   \n",
       " 2  240  244  248  252  256  260  264  268  272  276  ...  0.521199   1.0   \n",
       " \n",
       "    f146  f147      f148      f149      f150      f151     f152    target  \n",
       " 0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.388170  \n",
       " 1   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.643288  \n",
       " 2   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267  0.53624  0.458253  \n",
       " \n",
       " [3 rows x 273 columns],\n",
       "     f1        f2    f3   f4        f5   f6   f7   f8        f9  f10  ...  \\\n",
       " 0  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " 1  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " 2  1.0  0.985647  30.0  0.0  1.098661  0.0  0.0  0.0  1.290323  0.0  ...   \n",
       " \n",
       "        f144  f145  f146  f147      f148      f149      f150      f151  \\\n",
       " 0  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " 1  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " 2  0.521199   1.0   1.0   0.9  2.931081 -0.360864  0.333636 -0.568267   \n",
       " \n",
       "       f152    target  \n",
       " 0  0.53624  0.388170  \n",
       " 1  0.53624  0.643288  \n",
       " 2  0.53624  0.458253  \n",
       " \n",
       " [3 rows x 153 columns])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Sample TS\n",
    "linear_data = linear_data = np.arange(360).reshape(3, 30, 4)  # Creates an array with values from 0 to 1199\n",
    "linear_data\n",
    "\n",
    "np.random.seed(42)  # For reproducibility\n",
    "random_data = np.random.rand(3, 30, 4)\n",
    "random_y = np.random.rand(3)\n",
    "random_data\n",
    "\n",
    "prepare_data(linear_data, random_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvAutogluon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
