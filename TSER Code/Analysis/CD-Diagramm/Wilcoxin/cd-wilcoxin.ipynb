{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Hassan Ismail Fawaz <hassan.ismail-fawaz@uha.fr>\n",
    "#         Germain Forestier <germain.forestier@uha.fr>\n",
    "#         Jonathan Weber <jonathan.weber@uha.fr>\n",
    "#         Lhassane Idoumghar <lhassane.idoumghar@uha.fr>\n",
    "#         Pierre-Alain Muller <pierre-alain.muller@uha.fr>\n",
    "# License: GPL3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "matplotlib.rcParams['font.family'] = 'sans-serif'\n",
    "#matplotlib.rcParams['font.sans-serif'] = 'Arial'\n",
    "matplotlib.rcParams['font.sans-serif'] = ['DejaVu Sans', 'sans-serif']\n",
    "\n",
    "\n",
    "import operator\n",
    "import math\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.stats import friedmanchisquare\n",
    "import networkx\n",
    "\n",
    "# inspired from orange3 https://docs.orange.biolab.si/3/data-mining-library/reference/evaluation.cd.html\n",
    "def graph_ranks(avranks, names, p_values, cd=None, cdmethod=None, lowv=None, highv=None,\n",
    "                width=6, textspace=1, reverse=False, filename=None, labels=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Draws a CD graph, which is used to display  the differences in methods'\n",
    "    performance. See Janez Demsar, Statistical Comparisons of Classifiers over\n",
    "    Multiple Data Sets, 7(Jan):1--30, 2006.\n",
    "\n",
    "    Needs matplotlib to work.\n",
    "\n",
    "    The image is ploted on `plt` imported using\n",
    "    `import matplotlib.pyplot as plt`.\n",
    "\n",
    "    Args:\n",
    "        avranks (list of float): average ranks of methods.\n",
    "        names (list of str): names of methods.\n",
    "        cd (float): Critical difference used for statistically significance of\n",
    "            difference between methods.\n",
    "        cdmethod (int, optional): the method that is compared with other methods\n",
    "            If omitted, show pairwise comparison of methods\n",
    "        lowv (int, optional): the lowest shown rank\n",
    "        highv (int, optional): the highest shown rank\n",
    "        width (int, optional): default width in inches (default: 6)\n",
    "        textspace (int, optional): space on figure sides (in inches) for the\n",
    "            method names (default: 1)\n",
    "        reverse (bool, optional):  if set to `True`, the lowest rank is on the\n",
    "            right (default: `False`)\n",
    "        filename (str, optional): output file name (with extension). If not\n",
    "            given, the function does not write a file.\n",
    "        labels (bool, optional): if set to `True`, the calculated avg rank\n",
    "        values will be displayed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import matplotlib\n",
    "        import matplotlib.pyplot as plt\n",
    "        from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
    "    except ImportError:\n",
    "        raise ImportError(\"Function graph_ranks requires matplotlib.\")\n",
    "\n",
    "    width = float(width)\n",
    "    textspace = float(textspace)\n",
    "\n",
    "    def nth(l, n):\n",
    "        \"\"\"\n",
    "        Returns only nth elemnt in a list.\n",
    "        \"\"\"\n",
    "        n = lloc(l, n)\n",
    "        return [a[n] for a in l]\n",
    "\n",
    "    def lloc(l, n):\n",
    "        \"\"\"\n",
    "        List location in list of list structure.\n",
    "        Enable the use of negative locations:\n",
    "        -1 is the last element, -2 second last...\n",
    "        \"\"\"\n",
    "        if n < 0:\n",
    "            return len(l[0]) + n\n",
    "        else:\n",
    "            return n\n",
    "\n",
    "    def mxrange(lr):\n",
    "        \"\"\"\n",
    "        Multiple xranges. Can be used to traverse matrices.\n",
    "        This function is very slow due to unknown number of\n",
    "        parameters.\n",
    "\n",
    "        >>> mxrange([3,5])\n",
    "        [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
    "\n",
    "        >>> mxrange([[3,5,1],[9,0,-3]])\n",
    "        [(3, 9), (3, 6), (3, 3), (4, 9), (4, 6), (4, 3)]\n",
    "\n",
    "        \"\"\"\n",
    "        if not len(lr):\n",
    "            yield ()\n",
    "        else:\n",
    "            # it can work with single numbers\n",
    "            index = lr[0]\n",
    "            if isinstance(index, int):\n",
    "                index = [index]\n",
    "            for a in range(*index):\n",
    "                for b in mxrange(lr[1:]):\n",
    "                    yield tuple([a] + list(b))\n",
    "\n",
    "    def print_figure(fig, *args, **kwargs):\n",
    "        canvas = FigureCanvasAgg(fig)\n",
    "        canvas.print_figure(*args, **kwargs)\n",
    "\n",
    "    sums = avranks\n",
    "\n",
    "    nnames = names\n",
    "    ssums = sums\n",
    "\n",
    "    if lowv is None:\n",
    "        lowv = min(1, int(math.floor(min(ssums))))\n",
    "    if highv is None:\n",
    "        highv = max(len(avranks), int(math.ceil(max(ssums))))\n",
    "\n",
    "    cline = 0.4\n",
    "\n",
    "    k = len(sums)\n",
    "\n",
    "    lines = None\n",
    "\n",
    "    linesblank = 0\n",
    "    scalewidth = width - 2 * textspace\n",
    "\n",
    "    def rankpos(rank):\n",
    "        if not reverse:\n",
    "            a = rank - lowv\n",
    "        else:\n",
    "            a = highv - rank\n",
    "        return textspace + scalewidth / (highv - lowv) * a\n",
    "\n",
    "    distanceh = 0.25\n",
    "\n",
    "    cline += distanceh\n",
    "\n",
    "    # calculate height needed height of an image\n",
    "    minnotsignificant = max(2 * 0.2, linesblank)\n",
    "    height = cline + ((k + 1) / 2) * 0.2 + minnotsignificant\n",
    "\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    fig.set_facecolor('white')\n",
    "    ax = fig.add_axes([0, 0, 1, 1])  # reverse y axis\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    hf = 1. / height  # height factor\n",
    "    wf = 1. / width\n",
    "\n",
    "    def hfl(l):\n",
    "        return [a * hf for a in l]\n",
    "\n",
    "    def wfl(l):\n",
    "        return [a * wf for a in l]\n",
    "\n",
    "    # Upper left corner is (0,0).\n",
    "    ax.plot([0, 1], [0, 1], c=\"w\")\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(1, 0)\n",
    "\n",
    "    def line(l, color='k', **kwargs):\n",
    "        \"\"\"\n",
    "        Input is a list of pairs of points.\n",
    "        \"\"\"\n",
    "        ax.plot(wfl(nth(l, 0)), hfl(nth(l, 1)), color=color, **kwargs)\n",
    "\n",
    "    def text(x, y, s, *args, **kwargs):\n",
    "        ax.text(wf * x, hf * y, s, *args, **kwargs)\n",
    "\n",
    "    line([(textspace, cline), (width - textspace, cline)], linewidth=2)\n",
    "\n",
    "    bigtick = 0.3\n",
    "    smalltick = 0.15\n",
    "    linewidth = 2.0\n",
    "    linewidth_sign = 4.0\n",
    "\n",
    "    tick = None\n",
    "    for a in list(np.arange(lowv, highv, 0.5)) + [highv]:\n",
    "        tick = smalltick\n",
    "        if a == int(a):\n",
    "            tick = bigtick\n",
    "        line([(rankpos(a), cline - tick / 2),\n",
    "              (rankpos(a), cline)],\n",
    "             linewidth=2)\n",
    "\n",
    "    for a in range(lowv, highv + 1):\n",
    "        text(rankpos(a), cline - tick / 2 - 0.05, str(a),\n",
    "             ha=\"center\", va=\"bottom\", size=16)\n",
    "\n",
    "    k = len(ssums)\n",
    "\n",
    "    def filter_names(name):\n",
    "        return name\n",
    "\n",
    "    space_between_names = 0.24\n",
    "\n",
    "    for i in range(math.ceil(k / 2)):\n",
    "        chei = cline + minnotsignificant + i * space_between_names\n",
    "        line([(rankpos(ssums[i]), cline),\n",
    "              (rankpos(ssums[i]), chei),\n",
    "              (textspace - 0.1, chei)],\n",
    "             linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + 0.3, chei - 0.075, format(ssums[i], '.4f'), ha=\"right\", va=\"center\", size=10)\n",
    "        text(textspace - 0.2, chei, filter_names(nnames[i]), ha=\"right\", va=\"center\", size=16)\n",
    "\n",
    "    for i in range(math.ceil(k / 2), k):\n",
    "        chei = cline + minnotsignificant + (k - i - 1) * space_between_names\n",
    "        line([(rankpos(ssums[i]), cline),\n",
    "              (rankpos(ssums[i]), chei),\n",
    "              (textspace + scalewidth + 0.1, chei)],\n",
    "             linewidth=linewidth)\n",
    "        if labels:\n",
    "            text(textspace + scalewidth - 0.3, chei - 0.075, format(ssums[i], '.4f'), ha=\"left\", va=\"center\", size=10)\n",
    "        text(textspace + scalewidth + 0.2, chei, filter_names(nnames[i]),\n",
    "             ha=\"left\", va=\"center\", size=16)\n",
    "\n",
    "    # no-significance lines\n",
    "    def draw_lines(lines, side=0.05, height=0.1):\n",
    "        start = cline + 0.2\n",
    "\n",
    "        for l, r in lines:\n",
    "            line([(rankpos(ssums[l]) - side, start),\n",
    "                  (rankpos(ssums[r]) + side, start)],\n",
    "                 linewidth=linewidth_sign)\n",
    "            start += height\n",
    "            print('drawing: ', l, r)\n",
    "\n",
    "    # draw_lines(lines)\n",
    "    start = cline + 0.2\n",
    "    side = -0.02\n",
    "    height = 0.1\n",
    "\n",
    "    # draw no significant lines\n",
    "    # get the cliques\n",
    "    cliques = form_cliques(p_values, nnames)\n",
    "    i = 1\n",
    "    achieved_half = False\n",
    "    print(nnames)\n",
    "    for clq in cliques:\n",
    "        if len(clq) == 1:\n",
    "            continue\n",
    "        print(clq)\n",
    "        min_idx = np.array(clq).min()\n",
    "        max_idx = np.array(clq).max()\n",
    "        if min_idx >= len(nnames) / 2 and achieved_half == False:\n",
    "            start = cline + 0.25\n",
    "            achieved_half = True\n",
    "        line([(rankpos(ssums[min_idx]) - side, start),\n",
    "              (rankpos(ssums[max_idx]) + side, start)],\n",
    "             linewidth=linewidth_sign)\n",
    "        start += height\n",
    "\n",
    "\n",
    "def form_cliques(p_values, nnames):\n",
    "    \"\"\"\n",
    "    This method forms the cliques\n",
    "    \"\"\"\n",
    "    # first form the numpy matrix data\n",
    "    m = len(nnames)\n",
    "    g_data = np.zeros((m, m), dtype=np.int64)\n",
    "    for p in p_values:\n",
    "        if p[3] == False:\n",
    "            i = np.where(nnames == p[0])[0][0]\n",
    "            j = np.where(nnames == p[1])[0][0]\n",
    "            min_i = min(i, j)\n",
    "            max_j = max(i, j)\n",
    "            g_data[min_i, max_j] = 1\n",
    "\n",
    "    g = networkx.Graph(g_data)\n",
    "    return networkx.find_cliques(g)\n",
    "\n",
    "\n",
    "def draw_cd_diagram(df_perf=None, alpha=0.05, title=None, labels=False):\n",
    "    \"\"\"\n",
    "    Draws the critical difference diagram given the list of pairwise classifiers that are\n",
    "    significant or not\n",
    "    \"\"\"\n",
    "    p_values, average_ranks, _ = wilcoxon_holm(df_perf=df_perf, alpha=alpha)\n",
    "\n",
    "    print()\n",
    "    print('Average Ranks:')\n",
    "\n",
    "    print(average_ranks)\n",
    "    print()\n",
    "\n",
    "    print('P-Values')\n",
    "    for p in p_values:\n",
    "        print(p)\n",
    "    print()\n",
    "\n",
    "    graph_ranks(average_ranks.values, average_ranks.keys(), p_values,\n",
    "                cd=None, reverse=True, width=9, textspace=1.5, labels=labels)\n",
    "\n",
    "    font = {'family': 'sans-serif',\n",
    "        'color':  'black',\n",
    "        'weight': 'normal',\n",
    "        'size': 22,\n",
    "        }\n",
    "    if title:\n",
    "        plt.title(title,fontdict=font, y=0.9, x=0.5)\n",
    "    plt.savefig('cd-diagram.png',bbox_inches='tight')\n",
    "\n",
    "def wilcoxon_holm(alpha=0.05, df_perf=None):\n",
    "    \"\"\"\n",
    "    Applies the wilcoxon signed rank test between each pair of algorithm and then use Holm\n",
    "    to reject the null's hypothesis\n",
    "    \"\"\"\n",
    "    print(pd.unique(df_perf['classifier_name']))\n",
    "    # count the number of tested datasets per classifier\n",
    "    df_counts = pd.DataFrame({'count': df_perf.groupby(\n",
    "        ['classifier_name']).size()}).reset_index()\n",
    "    # get the maximum number of tested datasets\n",
    "    max_nb_datasets = df_counts['count'].max()\n",
    "    # get the list of classifiers who have been tested on nb_max_datasets\n",
    "    classifiers = list(df_counts.loc[df_counts['count'] == max_nb_datasets]\n",
    "                       ['classifier_name'])\n",
    "    # test the null hypothesis using friedman before doing a post-hoc analysis\n",
    "    friedman_p_value = friedmanchisquare(*(\n",
    "        np.array(df_perf.loc[df_perf['classifier_name'] == c]['accuracy'])\n",
    "        for c in classifiers))[1]\n",
    "    if friedman_p_value >= alpha:\n",
    "        # then the null hypothesis over the entire classifiers cannot be rejected\n",
    "        print('the null hypothesis over the entire classifiers cannot be rejected')\n",
    "        exit()\n",
    "    # get the number of classifiers\n",
    "    m = len(classifiers)\n",
    "    # init array that contains the p-values calculated by the Wilcoxon signed rank test\n",
    "    p_values = []\n",
    "    # loop through the algorithms to compare pairwise\n",
    "    for i in range(m - 1):\n",
    "        # get the name of classifier one\n",
    "        classifier_1 = classifiers[i]\n",
    "        # get the performance of classifier one\n",
    "        perf_1 = np.array(df_perf.loc[df_perf['classifier_name'] == classifier_1]['accuracy']\n",
    "                          , dtype=np.float64)\n",
    "        for j in range(i + 1, m):\n",
    "            # get the name of the second classifier\n",
    "            classifier_2 = classifiers[j]\n",
    "            # get the performance of classifier one\n",
    "            perf_2 = np.array(df_perf.loc[df_perf['classifier_name'] == classifier_2]\n",
    "                              ['accuracy'], dtype=np.float64)\n",
    "            # calculate the p_value\n",
    "            p_value = wilcoxon(perf_1, perf_2, zero_method='pratt')[1]\n",
    "            # appen to the list\n",
    "            p_values.append((classifier_1, classifier_2, p_value, False))\n",
    "    # get the number of hypothesis\n",
    "    k = len(p_values)\n",
    "    # sort the list in acsending manner of p-value\n",
    "    p_values.sort(key=operator.itemgetter(2))\n",
    "\n",
    "    # loop through the hypothesis\n",
    "    for i in range(k):\n",
    "        # correct alpha with holm\n",
    "        new_alpha = float(alpha / (k - i))\n",
    "        # test if significant after holm's correction of alpha\n",
    "        if p_values[i][2] <= new_alpha:\n",
    "            p_values[i] = (p_values[i][0], p_values[i][1], p_values[i][2], True)\n",
    "        else:\n",
    "            # stop\n",
    "            break\n",
    "    # compute the average ranks to be returned (useful for drawing the cd diagram)\n",
    "    # sort the dataframe of performances\n",
    "    sorted_df_perf = df_perf.loc[df_perf['classifier_name'].isin(classifiers)]. \\\n",
    "        sort_values(['classifier_name', 'dataset_name'])\n",
    "    # get the rank data\n",
    "    rank_data = np.array(sorted_df_perf['accuracy']).reshape(m, max_nb_datasets)\n",
    "\n",
    "    # create the data frame containg the accuracies\n",
    "    df_ranks = pd.DataFrame(data=rank_data, index=np.sort(classifiers), columns=\n",
    "    np.unique(sorted_df_perf['dataset_name']))\n",
    "\n",
    "    # number of wins\n",
    "    print('Number of wins')\n",
    "    dfff = df_ranks.rank(ascending=False)\n",
    "    print(dfff[dfff == 1.0].sum(axis=1))\n",
    "\n",
    "    # average the ranks\n",
    "    average_ranks = df_ranks.rank(ascending=False).mean(axis=1).sort_values(ascending=False)\n",
    "    # return the p-values and the average ranks\n",
    "    return p_values, average_ranks, max_nb_datasets\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining the outputs after tests:\n",
    "\n",
    "The higher the Accuracy Value, the better! So we don't have to adapt anything.\n",
    "\n",
    "Only 6 wins out of 8 Datasets because in 2 Datasets there are two winners!\n",
    "\n",
    "\n",
    "Outputs after testing:\n",
    "- When including first 0dval, null hypothesis gets rejected\n",
    "- without for rmse: weird connections\n",
    "- for msmape: okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'rmse_FLAML Results_count_df_with_0dval.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# From the example data, we tiny values win over high values! So we divide the counts by one!\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#path = 'msmape_FLAML Results_count_df_with_0dval.csv'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrmse_FLAML Results_count_df_with_0dval.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m df_perf \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#df_perf['accuracy'] = 1/ (df_perf['accuracy'] +1)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Test if values have influencs on the test\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#df_perf['accuracy'] = 1/df_perf['accuracy'] * 10 \u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# I assume the output is the\u001b[39;00m\n\u001b[1;32m     20\u001b[0m draw_cd_diagram(df_perf\u001b[38;5;241m=\u001b[39mdf_perf, title\u001b[38;5;241m=\u001b[39mpath, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'rmse_FLAML Results_count_df_with_0dval.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# From the example data, we tiny values win over high values! So we divide the counts by one!\n",
    "\n",
    "\n",
    "#path = 'msmape_FLAML Results_count_df.csv'\n",
    "#path = 'rmse_FLAML Results_count_df.csv'\n",
    "\n",
    "#path = 'msmape_FLAML Results_count_df_with_0dval.csv'\n",
    "path = 'rmse_FLAML Results_count_df_with_0dval.csv'\n",
    "\n",
    "\n",
    "df_perf = pd.read_csv(path, index_col=False)\n",
    "\n",
    "#df_perf['accuracy'] = 1/ (df_perf['accuracy'] +1)\n",
    "\n",
    "# Test if values have influencs on the test\n",
    "#df_perf['accuracy'] = 1/df_perf['accuracy'] * 10 \n",
    "\n",
    "# I assume the output is the\n",
    "\n",
    "draw_cd_diagram(df_perf=df_perf, title=path, labels=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dwt</td>\n",
       "      <td>AppliancesEnergy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dft</td>\n",
       "      <td>AppliancesEnergy</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dct</td>\n",
       "      <td>AppliancesEnergy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dwt</td>\n",
       "      <td>NewsTitleSentiment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dft</td>\n",
       "      <td>NewsTitleSentiment</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dct</td>\n",
       "      <td>NewsTitleSentiment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dwt</td>\n",
       "      <td>BenzeneConcentration</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dft</td>\n",
       "      <td>BenzeneConcentration</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dct</td>\n",
       "      <td>BenzeneConcentration</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dwt</td>\n",
       "      <td>BeijingPM25Quality</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dft</td>\n",
       "      <td>BeijingPM25Quality</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dct</td>\n",
       "      <td>BeijingPM25Quality</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>dwt</td>\n",
       "      <td>IEEEPPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dft</td>\n",
       "      <td>IEEEPPG</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>dct</td>\n",
       "      <td>IEEEPPG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dwt</td>\n",
       "      <td>FloodModeling1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dft</td>\n",
       "      <td>FloodModeling1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dct</td>\n",
       "      <td>FloodModeling1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>dwt</td>\n",
       "      <td>HouseholdPowerConsumption1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>dft</td>\n",
       "      <td>HouseholdPowerConsumption1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dct</td>\n",
       "      <td>HouseholdPowerConsumption1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>dwt</td>\n",
       "      <td>Covid3Month</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>dft</td>\n",
       "      <td>Covid3Month</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dct</td>\n",
       "      <td>Covid3Month</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   classifier_name                dataset_name  accuracy\n",
       "0              dwt            AppliancesEnergy         0\n",
       "1              dft            AppliancesEnergy         3\n",
       "2              dct            AppliancesEnergy         2\n",
       "3              dwt          NewsTitleSentiment         1\n",
       "4              dft          NewsTitleSentiment         2\n",
       "5              dct          NewsTitleSentiment         0\n",
       "6              dwt        BenzeneConcentration         6\n",
       "7              dft        BenzeneConcentration         4\n",
       "8              dct        BenzeneConcentration         4\n",
       "9              dwt          BeijingPM25Quality         6\n",
       "10             dft          BeijingPM25Quality         5\n",
       "11             dct          BeijingPM25Quality         5\n",
       "12             dwt                     IEEEPPG         1\n",
       "13             dft                     IEEEPPG         2\n",
       "14             dct                     IEEEPPG         1\n",
       "15             dwt              FloodModeling1         5\n",
       "16             dft              FloodModeling1         2\n",
       "17             dct              FloodModeling1         0\n",
       "18             dwt  HouseholdPowerConsumption1         3\n",
       "19             dft  HouseholdPowerConsumption1         2\n",
       "20             dct  HouseholdPowerConsumption1         1\n",
       "21             dwt                 Covid3Month         3\n",
       "22             dft                 Covid3Month         1\n",
       "23             dct                 Covid3Month         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   dataset_name classifier_name    accuracy\n",
      "0              AppliancesEnergy       AutoGluon    2.155978\n",
      "1            BeijingPM10Quality       AutoGluon   108.25219\n",
      "2            BeijingPM25Quality       AutoGluon   75.187533\n",
      "3          BenzeneConcentration       AutoGluon    3.874767\n",
      "4                   Covid3Month       AutoGluon    0.040439\n",
      "..                          ...             ...         ...\n",
      "231              FloodModeling2       Inception     0.00729\n",
      "232  HouseholdPowerConsumption1       Inception  153.716402\n",
      "233  HouseholdPowerConsumption2       Inception   39.409826\n",
      "234                     IEEEPPG       Inception   23.903929\n",
      "235          NewsTitleSentiment       Inception    0.158558\n",
      "\n",
      "[177 rows x 3 columns]\n",
      "['AutoGluon' 'FLAML' 'FPCR' 'FPCR-Bspline' 'SVR' 'SVR Optimised'\n",
      " 'Random Forest' 'XGBoost' '1-NN-ED' '5-NN-ED' '1-NN-DTWD' '5-NN-DTWD'\n",
      " 'Rocket' 'FCN' 'ResNet' 'Inception']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "At least 3 sets of samples must be given for Friedman test, got 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15284/1600804317.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#melted_df['accuracy'] = melted_df['accuracy'] * -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmelted_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mdraw_cd_diagram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_perf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmelted_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AutoML-Results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_15284/283585981.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df_perf, alpha, title, labels)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \"\"\"\n\u001b[1;32m    282\u001b[0m     \u001b[0mDraws\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcritical\u001b[0m \u001b[0mdifference\u001b[0m \u001b[0mdiagram\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mpairwise\u001b[0m \u001b[0mclassifiers\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0msignificant\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \"\"\"\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mp_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_ranks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwilcoxon_holm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_perf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_perf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average Ranks:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15284/283585981.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(alpha, df_perf)\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;31m# get the list of classifiers who have been tested on nb_max_datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m     classifiers = list(df_counts.loc[df_counts['count'] == max_nb_datasets]\n\u001b[1;32m    323\u001b[0m                        ['classifier_name'])\n\u001b[1;32m    324\u001b[0m     \u001b[0;31m# test the null hypothesis using friedman before doing a post-hoc analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     friedman_p_value = friedmanchisquare(*(\n\u001b[0m\u001b[1;32m    326\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_perf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_perf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'classifier_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         for c in classifiers))[1]\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfriedman_p_value\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    569\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNaN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_reduced_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtuple_to_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhypotest_fun_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_add_reduced_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduced_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtuple_to_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.10/site-packages/scipy/stats/_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*samples)\u001b[0m\n\u001b[1;32m   9035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9036\u001b[0m     \"\"\"\n\u001b[1;32m   9037\u001b[0m     \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9038\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9039\u001b[0;31m         raise ValueError('At least 3 sets of samples must be given '\n\u001b[0m\u001b[1;32m   9040\u001b[0m                          f'for Friedman test, got {k}.')\n\u001b[1;32m   9041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9042\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: At least 3 sets of samples must be given for Friedman test, got 1."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the ODS file\n",
    "file_path = '/home/sim/Desktop/TS Extrinsic Regression/AutoML-Results.ods'\n",
    "result_df = pd.read_excel(file_path, engine='odf', sheet_name='result')\n",
    "\n",
    "# Transform the DataFrame to have classifier names as a single column\n",
    "melted_df = result_df.melt(id_vars=['Dataset Name'], var_name='classifier_name', value_name='accuracy')\n",
    "\n",
    "# Rename columns to match the desired output\n",
    "melted_df = melted_df.rename(columns={'Dataset Name': 'dataset_name'})\n",
    "\n",
    "# Drop any rows where accuracy is NaN\n",
    "melted_df = melted_df.dropna(subset=['accuracy'])\n",
    "\n",
    "# Now melted_df contains the required data\n",
    "\n",
    "# Now when you print a DataFrame, it will show all rows\n",
    "#print(melted_df)\n",
    "\n",
    "melted_df['accuracy'] = melted_df['accuracy'] * -1\n",
    "print(melted_df)\n",
    "\n",
    "draw_cd_diagram(df_perf=melted_df, title='AutoML-Results', labels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>classifier_name</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AppliancesEnergy</td>\n",
       "      <td>AutoGluon</td>\n",
       "      <td>-2.155978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BeijingPM10Quality</td>\n",
       "      <td>AutoGluon</td>\n",
       "      <td>-108.25219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BeijingPM25Quality</td>\n",
       "      <td>AutoGluon</td>\n",
       "      <td>-75.187533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BenzeneConcentration</td>\n",
       "      <td>AutoGluon</td>\n",
       "      <td>-3.874767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Covid3Month</td>\n",
       "      <td>AutoGluon</td>\n",
       "      <td>-0.040439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>FloodModeling2</td>\n",
       "      <td>Inception</td>\n",
       "      <td>-0.00729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>HouseholdPowerConsumption1</td>\n",
       "      <td>Inception</td>\n",
       "      <td>-153.716402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>HouseholdPowerConsumption2</td>\n",
       "      <td>Inception</td>\n",
       "      <td>-39.409826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>IEEEPPG</td>\n",
       "      <td>Inception</td>\n",
       "      <td>-23.903929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>NewsTitleSentiment</td>\n",
       "      <td>Inception</td>\n",
       "      <td>-0.158558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dataset_name classifier_name    accuracy\n",
       "0              AppliancesEnergy       AutoGluon   -2.155978\n",
       "1            BeijingPM10Quality       AutoGluon  -108.25219\n",
       "2            BeijingPM25Quality       AutoGluon  -75.187533\n",
       "3          BenzeneConcentration       AutoGluon   -3.874767\n",
       "4                   Covid3Month       AutoGluon   -0.040439\n",
       "..                          ...             ...         ...\n",
       "231              FloodModeling2       Inception    -0.00729\n",
       "232  HouseholdPowerConsumption1       Inception -153.716402\n",
       "233  HouseholdPowerConsumption2       Inception  -39.409826\n",
       "234                     IEEEPPG       Inception  -23.903929\n",
       "235          NewsTitleSentiment       Inception   -0.158558\n",
       "\n",
       "[177 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "melted_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
