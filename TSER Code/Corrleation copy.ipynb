{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from create_prepared_data_tsfresh import *\n",
    "from compression import calculateCompRatio, compress_dataset\n",
    "from utils.personal_utils import *\n",
    "\n",
    "import os\n",
    "import pywt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ds = {\n",
    "    'AppliancesEnergy':   '/home/sim/Desktop/TS Extrinsic Regression/data/AppliancesEnergy_TEST.ts',\n",
    "    'NewsTitleSentiment': '/home/sim/Desktop/TS Extrinsic Regression/data/NewsTitleSentiment_TEST.ts',\n",
    "    'BenzeneConcentration':'/home/sim/Desktop/TS Extrinsic Regression/data/BenzeneConcentration_TEST.ts',\n",
    "    'BeijingPM25Quality': '/home/sim/Desktop/TS Extrinsic Regression/data/BeijingPM25Quality_TEST.ts',\n",
    "\n",
    "    'IEEEPPG':            '/home/sim/Desktop/TS Extrinsic Regression/data/IEEEPPG_TEST.ts',\n",
    "    'FloodModeling1':     '/home/sim/Desktop/TS Extrinsic Regression/data/FloodModeling1_TEST.ts',\n",
    "    'HouseholdPowerConsumption1': '/home/sim/Desktop/TS Extrinsic Regression/data/HouseholdPowerConsumption1_TEST.ts',\n",
    "    'Covid3Month':              '/home/sim/Desktop/TS Extrinsic Regression/data/Covid3Month_TEST.ts'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps: Change common features to the common features of each starting test set!\n",
    "All other things stay the same!\n",
    "\n",
    "FOUND OUT: For each Dataset and Technique, the number of features of tsfresh are the same! Also for each Dataset we get the same features after tsfresh for each tq and compression strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "18649\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6217\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "6994\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "3886\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "778\n",
      "Number of overlapping features for AppliancesEnergy: dct 18649\n",
      "Number of overlapping features for AppliancesEnergy: dft 18649\n",
      "Number of overlapping features for AppliancesEnergy: dwt 18649\n",
      "Number of overlapping features for BenzeneConcentration: dct 6217\n",
      "Number of overlapping features for BenzeneConcentration: dft 6217\n",
      "Number of overlapping features for BenzeneConcentration: dwt 6217\n",
      "Number of overlapping features for BeijingPM25Quality: dct 6994\n",
      "Number of overlapping features for BeijingPM25Quality: dft 6994\n",
      "Number of overlapping features for BeijingPM25Quality: dwt 6994\n",
      "Number of overlapping features for IEEEPPG: dct 3886\n",
      "Number of overlapping features for IEEEPPG: dft 3886\n",
      "Number of overlapping features for IEEEPPG: dwt 3886\n",
      "Number of overlapping features for FloodModeling1: dct 778\n",
      "Number of overlapping features for FloodModeling1: dft 778\n",
      "Number of overlapping features for FloodModeling1: dwt 778\n",
      "Number of overlapping features for HouseholdPowerConsumption1: dct 3886\n",
      "Number of overlapping features for HouseholdPowerConsumption1: dft 3886\n",
      "Number of overlapping features for HouseholdPowerConsumption1: dwt 3886\n",
      "Number of overlapping features for Covid3Month: dct 778\n",
      "Number of overlapping features for Covid3Month: dft 778\n",
      "Number of overlapping features for Covid3Month: dwt 778\n",
      "\n",
      "Number of overlapping features for whole dct 778\n",
      "Number of overlapping features for whole dft 778\n",
      "Number of overlapping features for whole dwt 778\n",
      "\n",
      "Number of overlapping features for whole AppliancesEnergy 18649\n",
      "Number of overlapping features for whole BenzeneConcentration 6217\n",
      "Number of overlapping features for whole BeijingPM25Quality 6994\n",
      "Number of overlapping features for whole IEEEPPG 3886\n",
      "Number of overlapping features for whole FloodModeling1 778\n",
      "Number of overlapping features for whole HouseholdPowerConsumption1 3886\n",
      "Number of overlapping features for whole Covid3Month 778\n"
     ]
    }
   ],
   "source": [
    "# Code to show, that Each Datast has the same features\n",
    "dropout_values = [None, 0.5, 0.75, 0.85, 0.9, 0.95, 0.97, 0.99]\n",
    "log_path = '/home/sim/Desktop/TS Extrinsic Regression/All-Logs/' \n",
    "\n",
    "ds_names = [\n",
    "    'AppliancesEnergy',\n",
    "    #'NewsTitleSentiment',\n",
    "    'BenzeneConcentration',\n",
    "    'BeijingPM25Quality',\n",
    "    'IEEEPPG',\n",
    "    'FloodModeling1',\n",
    "    'HouseholdPowerConsumption1',\n",
    "    'Covid3Month'\n",
    "]\n",
    "\n",
    "tqs = ['dct', 'dft', 'dwt']\n",
    "\n",
    "common_features_dict = {}\n",
    "\n",
    "# Helper function to find common elements in lists\n",
    "def common_elements(lists):\n",
    "    if not lists:\n",
    "        return []\n",
    "    common = lists[0]\n",
    "    for lst in lists[1:]:\n",
    "        common = [elem for elem in common if elem in lst]\n",
    "    return common\n",
    "\n",
    "# Iterate over them to go for each value\n",
    "for ds_name in ds_names:\n",
    "\n",
    "\n",
    "    for tq in tqs:\n",
    "        path_to_runs = log_path + f'{ds_name}_Runs/'\n",
    "        common_features = None\n",
    "        features_lists = []\n",
    "\n",
    "        \n",
    "        for dval in dropout_values:\n",
    "            if dval is None:\n",
    "                 curr_df = pd.read_parquet('/home/sim/Desktop/TS Extrinsic Regression/features_dfs/' + ds_name + f'/NONE_NONE_{ds_name}_features_TEST')\n",
    "                 features_lists.append(curr_df.columns)\n",
    "                 print(len(curr_df.columns))\n",
    "\n",
    "            else:\n",
    "                curr_df = pd.read_parquet('/home/sim/Desktop/TS Extrinsic Regression/features_dfs/' + ds_name + f'/{dval}_{tq}_{ds_name}_features_TEST')\n",
    "                features_lists.append(curr_df.columns)\n",
    "                print(len(curr_df.columns))\n",
    "            \n",
    "        \n",
    "        common_features = common_elements(features_lists)\n",
    "        common_features_dict[(ds_name, tq)] = common_features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print overlapping for (Dataset,Comp_Alg) combinaton\n",
    "for (ds_name, tq), common_features in common_features_dict.items():\n",
    "    if common_features is not None:\n",
    "        print(f\"Number of overlapping features for {ds_name}: {tq} {len(common_features)}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "# Print num of overlapping for each tq\n",
    "overlap_per_tq = {}\n",
    "for tmp_tq in tqs:\n",
    "        overlap_per_tq[tmp_tq] = common_elements([common_features for (ds_name, tq), common_features in common_features_dict.items() if tq == tmp_tq])\n",
    "        print(f\"Number of overlapping features for whole {tmp_tq} {len(overlap_per_tq[tmp_tq])}\")\n",
    "print()\n",
    "\n",
    "\n",
    "# Print number of overlapping for each dataset\n",
    "overlapp_per_dataset = {}\n",
    "for tmp_dsname in ds_names:\n",
    "\n",
    "        overlapp_per_dataset[tmp_dsname] = common_elements([common_features for (ds_name, tq), common_features in common_features_dict.items() if ds_name == tmp_dsname])\n",
    "        print(f\"Number of overlapping features for whole {tmp_dsname} {len(overlapp_per_dataset[tmp_dsname])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HouseholdPowerConsumption1, dct, 0.5 correlation calculated\n",
      "HouseholdPowerConsumption1, dct, 0.75 correlation calculated\n",
      "HouseholdPowerConsumption1, dct, 0.85 correlation calculated\n",
      "HouseholdPowerConsumption1, dct, 0.9 correlation calculated\n",
      "HouseholdPowerConsumption1, dct, 0.95 correlation calculated\n",
      "HouseholdPowerConsumption1, dct, 0.97 correlation calculated\n",
      "HouseholdPowerConsumption1, dct, 0.99 correlation calculated\n",
      "HouseholdPowerConsumption1, dft, 0.5 correlation calculated\n",
      "HouseholdPowerConsumption1, dft, 0.75 correlation calculated\n",
      "HouseholdPowerConsumption1, dft, 0.85 correlation calculated\n",
      "HouseholdPowerConsumption1, dft, 0.9 correlation calculated\n",
      "HouseholdPowerConsumption1, dft, 0.95 correlation calculated\n",
      "HouseholdPowerConsumption1, dft, 0.97 correlation calculated\n",
      "HouseholdPowerConsumption1, dft, 0.99 correlation calculated\n",
      "HouseholdPowerConsumption1, dwt, 0.5 correlation calculated\n",
      "HouseholdPowerConsumption1, dwt, 0.75 correlation calculated\n",
      "HouseholdPowerConsumption1, dwt, 0.85 correlation calculated\n",
      "HouseholdPowerConsumption1, dwt, 0.9 correlation calculated\n",
      "HouseholdPowerConsumption1, dwt, 0.95 correlation calculated\n",
      "HouseholdPowerConsumption1, dwt, 0.97 correlation calculated\n",
      "HouseholdPowerConsumption1, dwt, 0.99 correlation calculated\n",
      "Covid3Month, dct, 0.5 correlation calculated\n",
      "Covid3Month, dct, 0.75 correlation calculated\n",
      "Covid3Month, dct, 0.85 correlation calculated\n",
      "Covid3Month, dct, 0.9 correlation calculated\n",
      "Covid3Month, dct, 0.95 correlation calculated\n",
      "Covid3Month, dct, 0.97 correlation calculated\n",
      "Covid3Month, dct, 0.99 correlation calculated\n",
      "Covid3Month, dft, 0.5 correlation calculated\n",
      "Covid3Month, dft, 0.75 correlation calculated\n",
      "Covid3Month, dft, 0.85 correlation calculated\n",
      "Covid3Month, dft, 0.9 correlation calculated\n",
      "Covid3Month, dft, 0.95 correlation calculated\n",
      "Covid3Month, dft, 0.97 correlation calculated\n",
      "Covid3Month, dft, 0.99 correlation calculated\n",
      "Covid3Month, dwt, 0.5 correlation calculated\n",
      "Covid3Month, dwt, 0.75 correlation calculated\n",
      "Covid3Month, dwt, 0.85 correlation calculated\n",
      "Covid3Month, dwt, 0.9 correlation calculated\n",
      "Covid3Month, dwt, 0.95 correlation calculated\n",
      "Covid3Month, dwt, 0.97 correlation calculated\n",
      "Covid3Month, dwt, 0.99 correlation calculated\n"
     ]
    }
   ],
   "source": [
    "# Calculate the correlation, we get a dict looking like: correlations[('AppliancesEnergy', 'dft', 0.5)] -> correlation\n",
    "dropout_values = [None, 0.5, 0.75, 0.85, 0.9, 0.95, 0.97, 0.99]\n",
    "log_path = '/home/sim/Desktop/TS Extrinsic Regression/All-Logs/' \n",
    "\n",
    "ds_names = [\n",
    "    #'NewsTitleSentiment',\n",
    "    #'BenzeneConcentration',\n",
    "    #'BeijingPM25Quality',\n",
    "    #'IEEEPPG',\n",
    "    #'FloodModeling1',\n",
    "    'HouseholdPowerConsumption1',\n",
    "    'Covid3Month',\n",
    "    #'AppliancesEnergy',\n",
    "]\n",
    "\n",
    "\n",
    "tqs = ['dct', 'dft', 'dwt']\n",
    "\n",
    "prepared_dfs = {}\n",
    "correlations = {}\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    path_to_runs = log_path + f'{ds_name}_Runs/'\n",
    "\n",
    "\n",
    "\n",
    "    features_raw = pd.read_parquet('/home/sim/Desktop/TS Extrinsic Regression/features_dfs/' + ds_name + f'/NONE_NONE_{ds_name}_features_TEST')\n",
    "    #features_raw = load_and_prepare_everything(all_ds[ds_name], None, None)[1].drop('target', axis=1)\n",
    "    \n",
    "    path_to_pred = path_to_runs + f'NONE_{ds_name}_20min_Flaml_f/predictions.npy'\n",
    "    prediction_raw = np.load(path_to_pred)\n",
    "    features_raw['prediction'] = prediction_raw\n",
    "\n",
    "\n",
    "    for tq in tqs:\n",
    "        prepared_dfs[(ds_name,tq,None)] = features_raw.copy() # bc different features for each technique\n",
    "\n",
    "        for dval in dropout_values[1:]:\n",
    "            \n",
    "\n",
    "            features = pd.read_parquet('/home/sim/Desktop/TS Extrinsic Regression/features_dfs/' + ds_name + f'/{dval}_{tq}_{ds_name}_features_TEST')\n",
    "            #features = load_and_prepare_everything(all_ds[ds_name], tq, dval)[1].drop('target', axis=1)\n",
    "            \n",
    "            path_to_pred = path_to_runs + f'{dval}_{tq}_{ds_name}_20min_Flaml_f/predictions.npy'\n",
    "\n",
    "            with open(path_to_pred, 'r') as file:\n",
    "                prediction = np.load(path_to_pred)\n",
    "\n",
    "\n",
    "            features['prediction'] = prediction\n",
    "            prepared_dfs[(ds_name,tq, dval)] = features.copy()\n",
    "\n",
    "\n",
    "            # Add Subtraction and Correlation\n",
    "            sub_df = (features_raw - features)\n",
    "            corrs = sub_df.corrwith(sub_df['prediction'])\n",
    "            correlations[(ds_name,tq,dval)] = corrs\n",
    "\n",
    "            print(f'{ds_name}, {tq}, {dval} correlation calculated')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Average Correlation of absolute value over each (ds_name, tq)\n",
    "# The Entries are Series object, the row name is the featuer name!\n",
    "corr_ds_name_tq = {}\n",
    "\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    \n",
    "\n",
    "    for tq in tqs:\n",
    "\n",
    "        # Initalize a df with same columns, rows but zero in each field\n",
    "        avg_corr = correlations[(ds_name,tq,0.5)].copy()\n",
    "        avg_corr[:] = 0\n",
    "        #print(avg_corr)\n",
    "\n",
    "        for d_val in dropout_values[1:]:\n",
    "            curr_corr_df = correlations[(ds_name,tq,d_val)].abs()  # take abs value\n",
    "            avg_corr = curr_corr_df + avg_corr\n",
    "        \n",
    "        avg_corr = avg_corr / len(dropout_values[1:])\n",
    "    \n",
    "        \n",
    "        corr_ds_name_tq[(ds_name, tq)] = avg_corr.sort_values(ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "corr_ds_name = {}\n",
    "for ds_name in ds_names:\n",
    "    corr_ds_name[ds_name] = corr_ds_name_tq[(ds_name, 'dct')]\n",
    "    corr_ds_name[ds_name] += corr_ds_name_tq[(ds_name, 'dft')]\n",
    "    corr_ds_name[ds_name] += corr_ds_name_tq[(ds_name, 'dwt')]\n",
    "    \n",
    "    corr_ds_name[ds_name] = corr_ds_name[ds_name].sort_values(ascending=False) / 3\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HouseholdPowerConsumption1\n",
      "prediction                                                        1.000000\n",
      "dim_5__autocorrelation__lag_3                                     0.187021\n",
      "dim_5__change_quantiles__f_agg_var__isabs_True__qh_1.0__ql_0.0    0.186411\n",
      "dim_5__autocorrelation__lag_2                                     0.184919\n",
      "dim_5__abs_energy                                                 0.184884\n",
      "                                                                    ...   \n",
      "dim_5__symmetry_looking__r_0.9500000000000001                          NaN\n",
      "dim_5__value_count__value_-1                                           NaN\n",
      "dim_5__value_count__value_0                                            NaN\n",
      "dim_5__value_count__value_1                                            NaN\n",
      "target                                                                 NaN\n",
      "Length: 3887, dtype: float64\n",
      "\n",
      "Covid3Month\n",
      "prediction                                                        1.000000\n",
      "dim_1__fft_coefficient__attr_angle__coeff_33                      0.228457\n",
      "dim_1__agg_linear_trend__attr_rvalue__chunk_len_5__f_agg_var      0.202756\n",
      "dim_1__fft_coefficient__attr_imag__coeff_10                       0.195852\n",
      "dim_1__agg_linear_trend__attr_rvalue__chunk_len_10__f_agg_var     0.185145\n",
      "                                                                    ...   \n",
      "dim_1__agg_linear_trend__attr_stderr__chunk_len_50__f_agg_mean         NaN\n",
      "dim_1__agg_linear_trend__attr_stderr__chunk_len_50__f_agg_var          NaN\n",
      "dim_1__ratio_beyond_r_sigma__r_10                                      NaN\n",
      "dim_1__query_similarity_count__query_None__threshold_0.0               NaN\n",
      "target                                                                 NaN\n",
      "Length: 779, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get Correlation over each dataset\n",
    "\n",
    "for ds_name in ds_names:\n",
    "    print(ds_name )\n",
    "    print(corr_ds_name[(ds_name)])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HouseholdPowerConsumption1 dct\n",
      "prediction                               3.000000\n",
      "dim_5__autocorrelation__lag_2            0.554756\n",
      "dim_5__cid_ce__normalize_False           0.551622\n",
      "dim_5__partial_autocorrelation__lag_1    0.545708\n",
      "dim_5__autocorrelation__lag_1            0.545708\n",
      "dim_5__cid_ce__normalize_True            0.547739\n",
      "dtype: float64\n",
      "\n",
      "HouseholdPowerConsumption1 dft\n",
      "prediction                        1.000000\n",
      "dim_5__abs_energy                 0.232301\n",
      "dim_5__variance                   0.232301\n",
      "dim_5__autocorrelation__lag_3     0.231683\n",
      "dim_5__autocorrelation__lag_2     0.230032\n",
      "dim_5__cid_ce__normalize_False    0.230000\n",
      "dtype: float64\n",
      "\n",
      "HouseholdPowerConsumption1 dwt\n",
      "prediction                                                       1.000000\n",
      "dim_2__ratio_value_number_to_time_series_length                  0.238860\n",
      "dim_2__sum_of_reoccurring_values                                 0.203753\n",
      "dim_2__percentage_of_reoccurring_datapoints_to_all_datapoints    0.190692\n",
      "dim_2__lempel_ziv_complexity__bins_10                            0.183391\n",
      "dim_5__ratio_value_number_to_time_series_length                  0.164335\n",
      "dtype: float64\n",
      "\n",
      "Covid3Month dct\n",
      "prediction                                                       3.000000\n",
      "dim_1__agg_linear_trend__attr_rvalue__chunk_len_10__f_agg_var    0.555434\n",
      "dim_1__agg_linear_trend__attr_rvalue__chunk_len_5__f_agg_var     0.608267\n",
      "dim_1__fft_coefficient__attr_imag__coeff_10                      0.587555\n",
      "dim_1__fft_coefficient__attr_real__coeff_4                       0.506779\n",
      "dim_1__fft_coefficient__attr_angle__coeff_33                     0.685370\n",
      "dtype: float64\n",
      "\n",
      "Covid3Month dft\n",
      "prediction                                                         1.000000\n",
      "dim_1__change_quantiles__f_agg_var__isabs_False__qh_1.0__ql_0.8    0.235385\n",
      "dim_1__fft_coefficient__attr_imag__coeff_10                        0.234309\n",
      "dim_1__fft_coefficient__attr_real__coeff_34                        0.214739\n",
      "dim_1__fft_coefficient__attr_angle__coeff_33                       0.209407\n",
      "dim_1__mean_change                                                 0.206923\n",
      "dtype: float64\n",
      "\n",
      "Covid3Month dwt\n",
      "prediction                                                         1.000000\n",
      "dim_1__fft_coefficient__attr_angle__coeff_33                       0.259906\n",
      "dim_1__change_quantiles__f_agg_mean__isabs_True__qh_1.0__ql_0.8    0.239159\n",
      "dim_1__fft_coefficient__attr_angle__coeff_28                       0.217316\n",
      "dim_1__fft_coefficient__attr_abs__coeff_32                         0.213633\n",
      "dim_1__fft_coefficient__attr_imag__coeff_8                         0.192957\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print for Each Combination the top 5 features\n",
    "for ds_name in ds_names:\n",
    "    for tq in tqs:\n",
    "        print(ds_name + \" \" + tq)\n",
    "        print(corr_ds_name_tq[(ds_name, tq)].head(6))\n",
    "        print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1__variance_larger_than_standard_deviation</th>\n",
       "      <th>dim_1__has_duplicate_max</th>\n",
       "      <th>dim_1__has_duplicate_min</th>\n",
       "      <th>dim_1__has_duplicate</th>\n",
       "      <th>dim_1__sum_values</th>\n",
       "      <th>dim_1__abs_energy</th>\n",
       "      <th>dim_1__mean_abs_change</th>\n",
       "      <th>dim_1__mean_change</th>\n",
       "      <th>dim_1__mean_second_derivative_central</th>\n",
       "      <th>dim_1__median</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_1__fourier_entropy__bins_100</th>\n",
       "      <th>dim_1__permutation_entropy__dimension_3__tau_1</th>\n",
       "      <th>dim_1__permutation_entropy__dimension_4__tau_1</th>\n",
       "      <th>dim_1__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>dim_1__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>dim_1__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>dim_1__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>dim_1__mean_n_absolute_max__number_of_maxima_7</th>\n",
       "      <th>target</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.170387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.696721</td>\n",
       "      <td>0.131571</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.26783</td>\n",
       "      <td>0.337792</td>\n",
       "      <td>0.341279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.010153</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.035518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.329684</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.003795</td>\n",
       "      <td>0.033880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.928932</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.036359</td>\n",
       "      <td>0.036359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.432289</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.545867</td>\n",
       "      <td>0.082988</td>\n",
       "      <td>0.036872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.031948</td>\n",
       "      <td>0.031948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.259314</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.388960</td>\n",
       "      <td>0.045109</td>\n",
       "      <td>0.052389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.656854</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>0.036207</td>\n",
       "      <td>0.036207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.397956</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.590990</td>\n",
       "      <td>0.127831</td>\n",
       "      <td>0.036872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220352</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.010153</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.036872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-7.071068</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>0.021298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220352</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.010153</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.044085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>0.238542</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.664482</td>\n",
       "      <td>0.262533</td>\n",
       "      <td>0.265153</td>\n",
       "      <td>0.26783</td>\n",
       "      <td>0.270567</td>\n",
       "      <td>0.273365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.035518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.397956</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.00000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.894291</td>\n",
       "      <td>48.757813</td>\n",
       "      <td>0.061076</td>\n",
       "      <td>0.059406</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.044194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220352</td>\n",
       "      <td>0.228721</td>\n",
       "      <td>0.362545</td>\n",
       "      <td>0.49837</td>\n",
       "      <td>0.569862</td>\n",
       "      <td>0.642618</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.447512</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>0.036872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows × 779 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    dim_1__variance_larger_than_standard_deviation  dim_1__has_duplicate_max  \\\n",
       "0                                              0.0                       0.0   \n",
       "1                                              0.0                       1.0   \n",
       "2                                              0.0                       1.0   \n",
       "3                                              0.0                       1.0   \n",
       "4                                              0.0                       1.0   \n",
       "..                                             ...                       ...   \n",
       "56                                             0.0                       1.0   \n",
       "57                                             0.0                       1.0   \n",
       "58                                             0.0                       0.0   \n",
       "59                                             0.0                       1.0   \n",
       "60                                             0.0                       1.0   \n",
       "\n",
       "    dim_1__has_duplicate_min  dim_1__has_duplicate  dim_1__sum_values  \\\n",
       "0                        0.0                   1.0           0.000000   \n",
       "1                        1.0                   1.0          10.000000   \n",
       "2                        1.0                   1.0          -2.928932   \n",
       "3                        1.0                   1.0           7.071068   \n",
       "4                        1.0                   1.0          -5.656854   \n",
       "..                       ...                   ...                ...   \n",
       "56                       1.0                   1.0           7.071068   \n",
       "57                       1.0                   1.0          -7.071068   \n",
       "58                       0.0                   1.0           0.000000   \n",
       "59                       1.0                   1.0           0.000000   \n",
       "60                       1.0                   1.0           6.894291   \n",
       "\n",
       "    dim_1__abs_energy  dim_1__mean_abs_change  dim_1__mean_change  \\\n",
       "0           25.000000                0.170387            0.000000   \n",
       "1           12.500000                0.015060            0.015060   \n",
       "2           25.000000                0.036359            0.036359   \n",
       "3           25.000000                0.031948            0.031948   \n",
       "4           30.500000                0.036207            0.036207   \n",
       "..                ...                     ...                 ...   \n",
       "56          12.500000                0.021298            0.021298   \n",
       "57          12.500000                0.021298            0.021298   \n",
       "58          49.000000                0.238542            0.000000   \n",
       "59           0.000000                0.000000            0.000000   \n",
       "60          48.757813                0.061076            0.059406   \n",
       "\n",
       "    dim_1__mean_second_derivative_central  dim_1__median  ...  \\\n",
       "0                                     0.0       0.000000  ...   \n",
       "1                                     0.0       0.000000  ...   \n",
       "2                                     0.0       0.000000  ...   \n",
       "3                                     0.0       0.000000  ...   \n",
       "4                                     0.0       0.000000  ...   \n",
       "..                                    ...            ...  ...   \n",
       "56                                    0.0       0.000000  ...   \n",
       "57                                    0.0       0.000000  ...   \n",
       "58                                    0.0       0.000000  ...   \n",
       "59                                    0.0       0.000000  ...   \n",
       "60                                    0.0      -0.044194  ...   \n",
       "\n",
       "    dim_1__fourier_entropy__bins_100  \\\n",
       "0                           3.696721   \n",
       "1                           0.329684   \n",
       "2                           1.432289   \n",
       "3                           1.259314   \n",
       "4                           1.397956   \n",
       "..                               ...   \n",
       "56                          0.220352   \n",
       "57                          0.220352   \n",
       "58                          3.664482   \n",
       "59                          1.397956   \n",
       "60                          0.220352   \n",
       "\n",
       "    dim_1__permutation_entropy__dimension_3__tau_1  \\\n",
       "0                                         0.131571   \n",
       "1                                        -0.000000   \n",
       "2                                        -0.000000   \n",
       "3                                        -0.000000   \n",
       "4                                        -0.000000   \n",
       "..                                             ...   \n",
       "56                                       -0.000000   \n",
       "57                                       -0.000000   \n",
       "58                                        0.262533   \n",
       "59                                       -0.000000   \n",
       "60                                        0.228721   \n",
       "\n",
       "    dim_1__permutation_entropy__dimension_4__tau_1  \\\n",
       "0                                         0.199100   \n",
       "1                                        -0.000000   \n",
       "2                                        -0.000000   \n",
       "3                                        -0.000000   \n",
       "4                                        -0.000000   \n",
       "..                                             ...   \n",
       "56                                       -0.000000   \n",
       "57                                       -0.000000   \n",
       "58                                        0.265153   \n",
       "59                                       -0.000000   \n",
       "60                                        0.362545   \n",
       "\n",
       "    dim_1__permutation_entropy__dimension_5__tau_1  \\\n",
       "0                                          0.26783   \n",
       "1                                         -0.00000   \n",
       "2                                         -0.00000   \n",
       "3                                         -0.00000   \n",
       "4                                         -0.00000   \n",
       "..                                             ...   \n",
       "56                                        -0.00000   \n",
       "57                                        -0.00000   \n",
       "58                                         0.26783   \n",
       "59                                        -0.00000   \n",
       "60                                         0.49837   \n",
       "\n",
       "    dim_1__permutation_entropy__dimension_6__tau_1  \\\n",
       "0                                         0.337792   \n",
       "1                                        -0.000000   \n",
       "2                                        -0.000000   \n",
       "3                                        -0.000000   \n",
       "4                                        -0.000000   \n",
       "..                                             ...   \n",
       "56                                       -0.000000   \n",
       "57                                       -0.000000   \n",
       "58                                        0.270567   \n",
       "59                                       -0.000000   \n",
       "60                                        0.569862   \n",
       "\n",
       "    dim_1__permutation_entropy__dimension_7__tau_1  \\\n",
       "0                                         0.341279   \n",
       "1                                        -0.000000   \n",
       "2                                        -0.000000   \n",
       "3                                        -0.000000   \n",
       "4                                        -0.000000   \n",
       "..                                             ...   \n",
       "56                                       -0.000000   \n",
       "57                                       -0.000000   \n",
       "58                                        0.273365   \n",
       "59                                       -0.000000   \n",
       "60                                        0.642618   \n",
       "\n",
       "    dim_1__query_similarity_count__query_None__threshold_0.0  \\\n",
       "0                                                 0.0          \n",
       "1                                                 0.0          \n",
       "2                                                 0.0          \n",
       "3                                                 0.0          \n",
       "4                                                 0.0          \n",
       "..                                                ...          \n",
       "56                                                0.0          \n",
       "57                                                0.0          \n",
       "58                                                0.0          \n",
       "59                                                0.0          \n",
       "60                                                0.0          \n",
       "\n",
       "    dim_1__mean_n_absolute_max__number_of_maxima_7    target  prediction  \n",
       "0                                         1.010153  0.011884    0.035518  \n",
       "1                                         1.250000  0.003795    0.033880  \n",
       "2                                         1.545867  0.082988    0.036872  \n",
       "3                                         1.388960  0.045109    0.052389  \n",
       "4                                         1.590990  0.127831    0.036872  \n",
       "..                                             ...       ...         ...  \n",
       "56                                        1.010153  0.021028    0.036872  \n",
       "57                                        1.010153  0.010999    0.044085  \n",
       "58                                        1.414214  0.181818    0.035518  \n",
       "59                                        0.000000  0.000000    0.035518  \n",
       "60                                        1.447512  0.043269    0.036872  \n",
       "\n",
       "[61 rows x 779 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To sort features\n",
    "\n",
    "import re\n",
    "def extract_fifth_number(column_name):\n",
    "    match = re.match(r'^.{4}(\\d+)', column_name)  # Match numbers after the first 4 characters\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    return float('inf')  # Use infinity for columns without a valid number\n",
    "\n",
    "# Create a dictionary with column names as keys and extracted numbers as values\n",
    "column_sort_order = {col: extract_fifth_number(col) for col in features.columns}\n",
    "\n",
    "# Sort columns based on the extracted numbers\n",
    "sorted_columns = sorted(column_sort_order, key=column_sort_order.get)\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "features_sorted = features[sorted_columns]\n",
    "features_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/sim/Desktop/TS Extrinsic Regression/0.5_dct_AppliancesEnergy_20min_Flaml_f/selected_features.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/sim/Desktop/TS Extrinsic Regression/0.5_dct_AppliancesEnergy_20min_Flaml_f/selected_features.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      3\u001b[0m     lines \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m      5\u001b[0m lines \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines]\n",
      "File \u001b[0;32m~/Desktop/TS Extrinsic Regression/.venvFlamlFwiz/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/sim/Desktop/TS Extrinsic Regression/0.5_dct_AppliancesEnergy_20min_Flaml_f/selected_features.txt'"
     ]
    }
   ],
   "source": [
    "file_path = '/home/sim/Desktop/TS Extrinsic Regression/0.5_dct_AppliancesEnergy_20min_Flaml_f/selected_features.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "lines = [line.strip() for line in lines]\n",
    "\n",
    "selected_features = features[lines]\n",
    "\n",
    "\n",
    "column_sort_order = {col: extract_fifth_number(col) for col in selected_features.columns}\n",
    "\n",
    "# Sort columns based on the extracted numbers\n",
    "sorted_columns = sorted(column_sort_order, key=column_sort_order.get)\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "sfeatures_sorted = selected_features[sorted_columns]\n",
    "sfeatures_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvFlamlFwiz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
